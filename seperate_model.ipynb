{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496610b8-dc45-4f2e-b611-c82ca0ba9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69951b-6bdc-467d-b82a-48c1886f6e5a",
   "metadata": {},
   "source": [
    "# 시드 및 모델의 기본적인 파라미터 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61a476d-24fc-4ef7-890f-e5972ebadfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "seed_everything(42)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd987-7c9e-4f54-971b-41e64888c74c",
   "metadata": {},
   "source": [
    "# GPU 확인 및 device에 사용할 gpu 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "762454ac-07d9-4704-ae04-bb309914f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "GPU 사용 가능 여부: True\n"
     ]
    }
   ],
   "source": [
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7155fc-26f1-40be-ab29-d7de927c8bf9",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6289b8ce-91e1-471b-96fe-1132efc0b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeperateDataset(Dataset): # 각 목표별 데이터셋 만들기\n",
    "    def __init__(self, df, transform, target):\n",
    "        self.df = df\n",
    "        self.img_paths = self.df['path'].tolist()\n",
    "        self.labels = self.df[target].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b160f-56f6-450f-8c5f-54f427c5739a",
   "metadata": {},
   "source": [
    "# transform 만들기\n",
    "### 아래 부분은 3x384x384 할지 3x224x224할지 조건에 따라 선택해서 사용하시면 됩니다.\n",
    "### 각각 resize 후에 80퍼센트만 남도록 crop을 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4e8711-2bdd-48c1-a1e9-46eab25730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((280,280)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((280,280)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 아래 영역을 마우스로 지정하고, 컨트롤키 + '/' 눌러서 주석 제거\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.Resize((480,480)),\n",
    "#         transforms.CenterCrop(384),\n",
    "#         transforms.RandomRotation(5),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'test': transforms.Compose([\n",
    "#         transforms.Resize((480,480)),\n",
    "#         transforms.CenterCrop(384),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2a827-8b24-4152-bb5b-a0157fc46ebe",
   "metadata": {},
   "source": [
    "# 학습할 데이터 불러오기\n",
    "### 이 아래 부분은 실험 조건에 따라서 주석처리하면서 돌리면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647ac103-89a5-4987-867a-c434a59bd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5:1:1\n",
    "#df = pd.read_csv(\"/opt/ml/code/total.csv\")\n",
    "\n",
    "# 1:1:1\n",
    "df = pd.read_csv(\"/opt/ml/code/total_111.csv\", index_col=None)\n",
    "list_columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c90afeb-0fe2-4909-b3ec-f2ed8a52ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maskOX</th>\n",
       "      <th>maskGB</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/train/images/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>/opt/ml/input/data/train/images/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>/opt/ml/input/data/train/images/006957_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>/opt/ml/input/data/train/images/006957_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  maskOX  maskGB  class  \\\n",
       "0          1    1       0     NaN      4   \n",
       "1          1    1       1     0.0     16   \n",
       "2          1    1       1     1.0     10   \n",
       "3          1    1       0     NaN      4   \n",
       "4          1    1       1     0.0     16   \n",
       "...      ...  ...     ...     ...    ...   \n",
       "8095       0    0       1     0.0     12   \n",
       "8096       0    0       1     1.0      6   \n",
       "8097       0    0       0     NaN      0   \n",
       "8098       0    0       1     0.0     12   \n",
       "8099       0    0       1     1.0      6   \n",
       "\n",
       "                                                   path  \n",
       "0     /opt/ml/input/data/train/images/000001_female_...  \n",
       "1     /opt/ml/input/data/train/images/000001_female_...  \n",
       "2     /opt/ml/input/data/train/images/000001_female_...  \n",
       "3     /opt/ml/input/data/train/images/000002_female_...  \n",
       "4     /opt/ml/input/data/train/images/000002_female_...  \n",
       "...                                                 ...  \n",
       "8095  /opt/ml/input/data/train/images/006957_male_As...  \n",
       "8096  /opt/ml/input/data/train/images/006957_male_As...  \n",
       "8097  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "8098  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "8099  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "\n",
       "[8100 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b983a77d-968a-44d8-8c54-d9ee56c33b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval/'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec3040-2721-4718-aabb-95c5142a9615",
   "metadata": {},
   "source": [
    "### 만들 타겟을 아래에 적어주세요 (gender/age/maskOX/maskGB/class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d11ac1e8-1ec2-41d7-85e4-9183fd525a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target =\"class\"\n",
    "list_columns.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062fed46-514f-48c6-8559-dee94cefe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[list_columns], df[target], test_size=0.2, stratify=df[target], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "539259c1-5d81-4826-a3fe-f7f5ac6c0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c503b5f4-b898-4b51-973f-8234d21089bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SeperateDataset(train_df, transform=data_transforms['train'], target=target)\n",
    "val_data = SeperateDataset(test_df, transform=data_transforms['test'], target=target)\n",
    "test_data = TestDataset(image_paths, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad2f7306-d2b6-4765-960c-e097c261b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def train(num_epochs, model, data_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    total_start_time = timeit.default_timer()\n",
    "    best_loss = 9999999\n",
    "    best_test_accuracy = 0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_f1 = 0\n",
    "        running_acc = 0\n",
    "        print('Epoch start..')\n",
    "        epoch_start_time = timeit.default_timer()\n",
    "        for i, (imgs, labels) in enumerate(data_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            ## 코드 시작 ##\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()         \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy = (labels == argmax).float().mean()\n",
    "            \n",
    "            f1 = f1_score(labels.cpu().numpy(), argmax.cpu().numpy(), average='macro')\n",
    "            epoch_f1 += f1\n",
    "            running_acc += accuracy\n",
    "            if (i+1) % 3 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%, F1_Score: {:.2f}'.format(\n",
    "                    epoch+1, num_epochs, i+1, len(data_loader), loss.item(), accuracy.item() * 100, f1))\n",
    "        print(\"------------Epoch Finish------------\")\n",
    "        print('Epoch [{}/{}], Accuracy: {:.2f}%, F1_Score: {:.2f}'.format(\n",
    "                    epoch+1, num_epochs, running_acc.item()/(i+1) * 100,epoch_f1/(i+1)))\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)\n",
    "        epoch_end_time = timeit.default_timer()\n",
    "        print(\"Epoch end..\")\n",
    "        print(f\"epoch time : {epoch_end_time-epoch_start_time}\")\n",
    "        epoch_acc = running_acc / (i+1)\n",
    "        \n",
    "        if best_test_accuracy < epoch_acc:\n",
    "            best_test_accuracy = epoch_acc\n",
    "            save_model(model, saved_dir)\n",
    "            early_stop_point = 0\n",
    "        else:\n",
    "            early_stop_point += 1\n",
    "        if early_stop_point == 3:\n",
    "            print('early_stopped')\n",
    "            break\n",
    "    print('End training..')\n",
    "    total_end_time = timeit.default_timer()\n",
    "    print(f\"total time : {total_end_time-total_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6500ffe5-8611-4bb5-b677-079864700979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch) )\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        epoch_f1 = 0\n",
    "        for i, (imgs, labels) in enumerate(data_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            ## 코드 시작 ##\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            ## 코드 종료 ##\n",
    "            total += imgs.size(0)\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item()\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            epoch_f1 += f1_score(labels.cpu().numpy(), argmax.cpu().numpy(), average='macro')\n",
    "        avrg_loss = total_loss / cnt\n",
    "        avrg_f1 = epoch_f1 / cnt\n",
    "        print('Validation #{}  Accuracy: {:.2f}% F1_Score: {:.2f} Average Loss: {:.4f}'.format(epoch, correct / total * 100,avrg_f1 ,avrg_loss))\n",
    "    model.train()\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd7ad5a3-e669-4dc7-b8b2-31e331232967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir, file_name='best_model.pt'):\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    check_point = {\n",
    "        'net': model.state_dict()\n",
    "    }\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(check_point,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6601b89-001e-443b-b3f4-f0f869e458f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5d4f22c-5938-4cea-8363-91b69567f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "class ViTBase32_224(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "\n",
    "        super(ViTBase32_224, self).__init__()\n",
    "\n",
    "        self.model = timm.create_model(\"vit_base_patch32_224\", pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaf2dac7-3f9a-40dc-86aa-c9bf0ab7259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target에 따라서 n_classes 정하면 된다.\n",
    "model = ViTBase32_224(n_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df9544eb-40b8-414e-a9be-58b6246e2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 끝에서 학습할 레이어의 수를 설정합니다.\n",
    "num_train_layer = 1\n",
    "\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    if i == len(list(model.parameters())) - num_train_layer:\n",
    "        break\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab078195-ffce-4e8a-b430-164d8dab9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "saved_dir = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/model'\n",
    "val_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab2de743-e772-4d9c-8259-698147230e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [32, 768, 7, 7]       2,360,064\n",
      "          Identity-2              [32, 49, 768]               0\n",
      "        PatchEmbed-3              [32, 49, 768]               0\n",
      "           Dropout-4              [32, 50, 768]               0\n",
      "         LayerNorm-5              [32, 50, 768]           1,536\n",
      "            Linear-6             [32, 50, 2304]       1,771,776\n",
      "           Dropout-7           [32, 12, 50, 50]               0\n",
      "            Linear-8              [32, 50, 768]         590,592\n",
      "           Dropout-9              [32, 50, 768]               0\n",
      "        Attention-10              [32, 50, 768]               0\n",
      "         Identity-11              [32, 50, 768]               0\n",
      "        LayerNorm-12              [32, 50, 768]           1,536\n",
      "           Linear-13             [32, 50, 3072]       2,362,368\n",
      "             GELU-14             [32, 50, 3072]               0\n",
      "          Dropout-15             [32, 50, 3072]               0\n",
      "           Linear-16              [32, 50, 768]       2,360,064\n",
      "          Dropout-17              [32, 50, 768]               0\n",
      "              Mlp-18              [32, 50, 768]               0\n",
      "         Identity-19              [32, 50, 768]               0\n",
      "            Block-20              [32, 50, 768]               0\n",
      "        LayerNorm-21              [32, 50, 768]           1,536\n",
      "           Linear-22             [32, 50, 2304]       1,771,776\n",
      "          Dropout-23           [32, 12, 50, 50]               0\n",
      "           Linear-24              [32, 50, 768]         590,592\n",
      "          Dropout-25              [32, 50, 768]               0\n",
      "        Attention-26              [32, 50, 768]               0\n",
      "         Identity-27              [32, 50, 768]               0\n",
      "        LayerNorm-28              [32, 50, 768]           1,536\n",
      "           Linear-29             [32, 50, 3072]       2,362,368\n",
      "             GELU-30             [32, 50, 3072]               0\n",
      "          Dropout-31             [32, 50, 3072]               0\n",
      "           Linear-32              [32, 50, 768]       2,360,064\n",
      "          Dropout-33              [32, 50, 768]               0\n",
      "              Mlp-34              [32, 50, 768]               0\n",
      "         Identity-35              [32, 50, 768]               0\n",
      "            Block-36              [32, 50, 768]               0\n",
      "        LayerNorm-37              [32, 50, 768]           1,536\n",
      "           Linear-38             [32, 50, 2304]       1,771,776\n",
      "          Dropout-39           [32, 12, 50, 50]               0\n",
      "           Linear-40              [32, 50, 768]         590,592\n",
      "          Dropout-41              [32, 50, 768]               0\n",
      "        Attention-42              [32, 50, 768]               0\n",
      "         Identity-43              [32, 50, 768]               0\n",
      "        LayerNorm-44              [32, 50, 768]           1,536\n",
      "           Linear-45             [32, 50, 3072]       2,362,368\n",
      "             GELU-46             [32, 50, 3072]               0\n",
      "          Dropout-47             [32, 50, 3072]               0\n",
      "           Linear-48              [32, 50, 768]       2,360,064\n",
      "          Dropout-49              [32, 50, 768]               0\n",
      "              Mlp-50              [32, 50, 768]               0\n",
      "         Identity-51              [32, 50, 768]               0\n",
      "            Block-52              [32, 50, 768]               0\n",
      "        LayerNorm-53              [32, 50, 768]           1,536\n",
      "           Linear-54             [32, 50, 2304]       1,771,776\n",
      "          Dropout-55           [32, 12, 50, 50]               0\n",
      "           Linear-56              [32, 50, 768]         590,592\n",
      "          Dropout-57              [32, 50, 768]               0\n",
      "        Attention-58              [32, 50, 768]               0\n",
      "         Identity-59              [32, 50, 768]               0\n",
      "        LayerNorm-60              [32, 50, 768]           1,536\n",
      "           Linear-61             [32, 50, 3072]       2,362,368\n",
      "             GELU-62             [32, 50, 3072]               0\n",
      "          Dropout-63             [32, 50, 3072]               0\n",
      "           Linear-64              [32, 50, 768]       2,360,064\n",
      "          Dropout-65              [32, 50, 768]               0\n",
      "              Mlp-66              [32, 50, 768]               0\n",
      "         Identity-67              [32, 50, 768]               0\n",
      "            Block-68              [32, 50, 768]               0\n",
      "        LayerNorm-69              [32, 50, 768]           1,536\n",
      "           Linear-70             [32, 50, 2304]       1,771,776\n",
      "          Dropout-71           [32, 12, 50, 50]               0\n",
      "           Linear-72              [32, 50, 768]         590,592\n",
      "          Dropout-73              [32, 50, 768]               0\n",
      "        Attention-74              [32, 50, 768]               0\n",
      "         Identity-75              [32, 50, 768]               0\n",
      "        LayerNorm-76              [32, 50, 768]           1,536\n",
      "           Linear-77             [32, 50, 3072]       2,362,368\n",
      "             GELU-78             [32, 50, 3072]               0\n",
      "          Dropout-79             [32, 50, 3072]               0\n",
      "           Linear-80              [32, 50, 768]       2,360,064\n",
      "          Dropout-81              [32, 50, 768]               0\n",
      "              Mlp-82              [32, 50, 768]               0\n",
      "         Identity-83              [32, 50, 768]               0\n",
      "            Block-84              [32, 50, 768]               0\n",
      "        LayerNorm-85              [32, 50, 768]           1,536\n",
      "           Linear-86             [32, 50, 2304]       1,771,776\n",
      "          Dropout-87           [32, 12, 50, 50]               0\n",
      "           Linear-88              [32, 50, 768]         590,592\n",
      "          Dropout-89              [32, 50, 768]               0\n",
      "        Attention-90              [32, 50, 768]               0\n",
      "         Identity-91              [32, 50, 768]               0\n",
      "        LayerNorm-92              [32, 50, 768]           1,536\n",
      "           Linear-93             [32, 50, 3072]       2,362,368\n",
      "             GELU-94             [32, 50, 3072]               0\n",
      "          Dropout-95             [32, 50, 3072]               0\n",
      "           Linear-96              [32, 50, 768]       2,360,064\n",
      "          Dropout-97              [32, 50, 768]               0\n",
      "              Mlp-98              [32, 50, 768]               0\n",
      "         Identity-99              [32, 50, 768]               0\n",
      "           Block-100              [32, 50, 768]               0\n",
      "       LayerNorm-101              [32, 50, 768]           1,536\n",
      "          Linear-102             [32, 50, 2304]       1,771,776\n",
      "         Dropout-103           [32, 12, 50, 50]               0\n",
      "          Linear-104              [32, 50, 768]         590,592\n",
      "         Dropout-105              [32, 50, 768]               0\n",
      "       Attention-106              [32, 50, 768]               0\n",
      "        Identity-107              [32, 50, 768]               0\n",
      "       LayerNorm-108              [32, 50, 768]           1,536\n",
      "          Linear-109             [32, 50, 3072]       2,362,368\n",
      "            GELU-110             [32, 50, 3072]               0\n",
      "         Dropout-111             [32, 50, 3072]               0\n",
      "          Linear-112              [32, 50, 768]       2,360,064\n",
      "         Dropout-113              [32, 50, 768]               0\n",
      "             Mlp-114              [32, 50, 768]               0\n",
      "        Identity-115              [32, 50, 768]               0\n",
      "           Block-116              [32, 50, 768]               0\n",
      "       LayerNorm-117              [32, 50, 768]           1,536\n",
      "          Linear-118             [32, 50, 2304]       1,771,776\n",
      "         Dropout-119           [32, 12, 50, 50]               0\n",
      "          Linear-120              [32, 50, 768]         590,592\n",
      "         Dropout-121              [32, 50, 768]               0\n",
      "       Attention-122              [32, 50, 768]               0\n",
      "        Identity-123              [32, 50, 768]               0\n",
      "       LayerNorm-124              [32, 50, 768]           1,536\n",
      "          Linear-125             [32, 50, 3072]       2,362,368\n",
      "            GELU-126             [32, 50, 3072]               0\n",
      "         Dropout-127             [32, 50, 3072]               0\n",
      "          Linear-128              [32, 50, 768]       2,360,064\n",
      "         Dropout-129              [32, 50, 768]               0\n",
      "             Mlp-130              [32, 50, 768]               0\n",
      "        Identity-131              [32, 50, 768]               0\n",
      "           Block-132              [32, 50, 768]               0\n",
      "       LayerNorm-133              [32, 50, 768]           1,536\n",
      "          Linear-134             [32, 50, 2304]       1,771,776\n",
      "         Dropout-135           [32, 12, 50, 50]               0\n",
      "          Linear-136              [32, 50, 768]         590,592\n",
      "         Dropout-137              [32, 50, 768]               0\n",
      "       Attention-138              [32, 50, 768]               0\n",
      "        Identity-139              [32, 50, 768]               0\n",
      "       LayerNorm-140              [32, 50, 768]           1,536\n",
      "          Linear-141             [32, 50, 3072]       2,362,368\n",
      "            GELU-142             [32, 50, 3072]               0\n",
      "         Dropout-143             [32, 50, 3072]               0\n",
      "          Linear-144              [32, 50, 768]       2,360,064\n",
      "         Dropout-145              [32, 50, 768]               0\n",
      "             Mlp-146              [32, 50, 768]               0\n",
      "        Identity-147              [32, 50, 768]               0\n",
      "           Block-148              [32, 50, 768]               0\n",
      "       LayerNorm-149              [32, 50, 768]           1,536\n",
      "          Linear-150             [32, 50, 2304]       1,771,776\n",
      "         Dropout-151           [32, 12, 50, 50]               0\n",
      "          Linear-152              [32, 50, 768]         590,592\n",
      "         Dropout-153              [32, 50, 768]               0\n",
      "       Attention-154              [32, 50, 768]               0\n",
      "        Identity-155              [32, 50, 768]               0\n",
      "       LayerNorm-156              [32, 50, 768]           1,536\n",
      "          Linear-157             [32, 50, 3072]       2,362,368\n",
      "            GELU-158             [32, 50, 3072]               0\n",
      "         Dropout-159             [32, 50, 3072]               0\n",
      "          Linear-160              [32, 50, 768]       2,360,064\n",
      "         Dropout-161              [32, 50, 768]               0\n",
      "             Mlp-162              [32, 50, 768]               0\n",
      "        Identity-163              [32, 50, 768]               0\n",
      "           Block-164              [32, 50, 768]               0\n",
      "       LayerNorm-165              [32, 50, 768]           1,536\n",
      "          Linear-166             [32, 50, 2304]       1,771,776\n",
      "         Dropout-167           [32, 12, 50, 50]               0\n",
      "          Linear-168              [32, 50, 768]         590,592\n",
      "         Dropout-169              [32, 50, 768]               0\n",
      "       Attention-170              [32, 50, 768]               0\n",
      "        Identity-171              [32, 50, 768]               0\n",
      "       LayerNorm-172              [32, 50, 768]           1,536\n",
      "          Linear-173             [32, 50, 3072]       2,362,368\n",
      "            GELU-174             [32, 50, 3072]               0\n",
      "         Dropout-175             [32, 50, 3072]               0\n",
      "          Linear-176              [32, 50, 768]       2,360,064\n",
      "         Dropout-177              [32, 50, 768]               0\n",
      "             Mlp-178              [32, 50, 768]               0\n",
      "        Identity-179              [32, 50, 768]               0\n",
      "           Block-180              [32, 50, 768]               0\n",
      "       LayerNorm-181              [32, 50, 768]           1,536\n",
      "          Linear-182             [32, 50, 2304]       1,771,776\n",
      "         Dropout-183           [32, 12, 50, 50]               0\n",
      "          Linear-184              [32, 50, 768]         590,592\n",
      "         Dropout-185              [32, 50, 768]               0\n",
      "       Attention-186              [32, 50, 768]               0\n",
      "        Identity-187              [32, 50, 768]               0\n",
      "       LayerNorm-188              [32, 50, 768]           1,536\n",
      "          Linear-189             [32, 50, 3072]       2,362,368\n",
      "            GELU-190             [32, 50, 3072]               0\n",
      "         Dropout-191             [32, 50, 3072]               0\n",
      "          Linear-192              [32, 50, 768]       2,360,064\n",
      "         Dropout-193              [32, 50, 768]               0\n",
      "             Mlp-194              [32, 50, 768]               0\n",
      "        Identity-195              [32, 50, 768]               0\n",
      "           Block-196              [32, 50, 768]               0\n",
      "       LayerNorm-197              [32, 50, 768]           1,536\n",
      "        Identity-198                  [32, 768]               0\n",
      "          Linear-199                   [32, 18]          13,842\n",
      "VisionTransformer-200                   [32, 18]               0\n",
      "================================================================\n",
      "Total params: 87,429,906\n",
      "Trainable params: 0\n",
      "Non-trainable params: 87,429,906\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 3059.40\n",
      "Params size (MB): 333.52\n",
      "Estimated Total Size (MB): 3411.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary_\n",
    "\n",
    "summary_(model,(3,224,224),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e425094-b760-46a8-9e7a-b406a452edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training..\n",
      "Epoch start..\n",
      "Epoch [1/200], Step [3/202], Loss: 0.7167, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [1/200], Step [6/202], Loss: 0.6050, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [9/202], Loss: 0.5435, Accuracy: 78.12%, F1_Score: 0.77\n",
      "Epoch [1/200], Step [12/202], Loss: 0.6677, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [1/200], Step [15/202], Loss: 0.7657, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [18/202], Loss: 0.7444, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [21/202], Loss: 0.6687, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [24/202], Loss: 0.7123, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [27/202], Loss: 0.6969, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [30/202], Loss: 0.8209, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [33/202], Loss: 0.9141, Accuracy: 50.00%, F1_Score: 0.45\n",
      "Epoch [1/200], Step [36/202], Loss: 0.7782, Accuracy: 53.12%, F1_Score: 0.49\n",
      "Epoch [1/200], Step [39/202], Loss: 0.7227, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [42/202], Loss: 0.7801, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [45/202], Loss: 0.6907, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [48/202], Loss: 0.7032, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [51/202], Loss: 0.7201, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [1/200], Step [54/202], Loss: 0.8068, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [57/202], Loss: 0.5231, Accuracy: 75.00%, F1_Score: 0.72\n",
      "Epoch [1/200], Step [60/202], Loss: 0.8101, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [1/200], Step [63/202], Loss: 0.9052, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [66/202], Loss: 0.7672, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [69/202], Loss: 0.7474, Accuracy: 56.25%, F1_Score: 0.55\n",
      "Epoch [1/200], Step [72/202], Loss: 0.7107, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [1/200], Step [75/202], Loss: 0.8272, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [1/200], Step [78/202], Loss: 0.7092, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [1/200], Step [81/202], Loss: 0.7357, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [1/200], Step [84/202], Loss: 0.7722, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [1/200], Step [87/202], Loss: 0.7034, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [90/202], Loss: 0.6904, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [93/202], Loss: 0.7386, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [96/202], Loss: 0.8772, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [1/200], Step [99/202], Loss: 0.7247, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [102/202], Loss: 0.7869, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [1/200], Step [105/202], Loss: 0.6461, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [1/200], Step [108/202], Loss: 0.6066, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [1/200], Step [111/202], Loss: 0.7027, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [114/202], Loss: 0.6682, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [117/202], Loss: 0.8493, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [120/202], Loss: 0.7183, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [1/200], Step [123/202], Loss: 0.8073, Accuracy: 46.88%, F1_Score: 0.47\n",
      "Epoch [1/200], Step [126/202], Loss: 0.6455, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [1/200], Step [129/202], Loss: 0.5141, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [1/200], Step [132/202], Loss: 0.5366, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [1/200], Step [135/202], Loss: 0.5694, Accuracy: 78.12%, F1_Score: 0.74\n",
      "Epoch [1/200], Step [138/202], Loss: 0.6737, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [141/202], Loss: 0.6962, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [1/200], Step [144/202], Loss: 0.7621, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [147/202], Loss: 0.8561, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [1/200], Step [150/202], Loss: 0.5927, Accuracy: 65.62%, F1_Score: 0.64\n",
      "Epoch [1/200], Step [153/202], Loss: 0.6994, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [156/202], Loss: 0.6318, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [1/200], Step [159/202], Loss: 0.6090, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [1/200], Step [162/202], Loss: 0.7128, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [165/202], Loss: 0.8225, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [168/202], Loss: 0.7465, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [171/202], Loss: 0.6896, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [174/202], Loss: 0.7234, Accuracy: 53.12%, F1_Score: 0.51\n",
      "Epoch [1/200], Step [177/202], Loss: 0.6682, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [1/200], Step [180/202], Loss: 0.6841, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [183/202], Loss: 0.7852, Accuracy: 50.00%, F1_Score: 0.47\n",
      "Epoch [1/200], Step [186/202], Loss: 0.6167, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [1/200], Step [189/202], Loss: 0.8356, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [1/200], Step [192/202], Loss: 0.7119, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [1/200], Step [195/202], Loss: 0.6709, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [1/200], Step [198/202], Loss: 0.6477, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [1/200], Step [201/202], Loss: 0.7571, Accuracy: 53.12%, F1_Score: 0.52\n",
      "------------Epoch Finish------------\n",
      "Epoch [1/200], Accuracy: 58.32%, F1_Score: 0.57\n",
      "Start validation #1\n",
      "Validation #1  Accuracy: 60.12% F1_Score: 0.59 Average Loss: 0.7080\n",
      "Best performance at epoch: 1\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.44074966502376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [01:03<3:31:30, 63.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [2/200], Step [3/202], Loss: 0.6868, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [6/202], Loss: 0.5950, Accuracy: 65.62%, F1_Score: 0.64\n",
      "Epoch [2/200], Step [9/202], Loss: 0.6895, Accuracy: 65.62%, F1_Score: 0.63\n",
      "Epoch [2/200], Step [12/202], Loss: 0.6797, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [15/202], Loss: 0.7317, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [2/200], Step [18/202], Loss: 0.6023, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [2/200], Step [21/202], Loss: 0.8645, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [2/200], Step [24/202], Loss: 0.6588, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [27/202], Loss: 0.6368, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [2/200], Step [30/202], Loss: 0.5190, Accuracy: 81.25%, F1_Score: 0.80\n",
      "Epoch [2/200], Step [33/202], Loss: 0.7417, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [2/200], Step [36/202], Loss: 0.6574, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [2/200], Step [39/202], Loss: 0.6730, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [2/200], Step [42/202], Loss: 0.7885, Accuracy: 56.25%, F1_Score: 0.55\n",
      "Epoch [2/200], Step [45/202], Loss: 0.6850, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [48/202], Loss: 0.7464, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [2/200], Step [51/202], Loss: 0.8397, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [2/200], Step [54/202], Loss: 0.7275, Accuracy: 56.25%, F1_Score: 0.55\n",
      "Epoch [2/200], Step [57/202], Loss: 0.4757, Accuracy: 78.12%, F1_Score: 0.76\n",
      "Epoch [2/200], Step [60/202], Loss: 0.7086, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [63/202], Loss: 0.7157, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [66/202], Loss: 0.8370, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [2/200], Step [69/202], Loss: 0.5421, Accuracy: 65.62%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [72/202], Loss: 0.7064, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [2/200], Step [75/202], Loss: 0.6762, Accuracy: 62.50%, F1_Score: 0.58\n",
      "Epoch [2/200], Step [78/202], Loss: 0.7637, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [2/200], Step [81/202], Loss: 0.5989, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [2/200], Step [84/202], Loss: 0.5651, Accuracy: 65.62%, F1_Score: 0.64\n",
      "Epoch [2/200], Step [87/202], Loss: 0.8452, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [2/200], Step [90/202], Loss: 0.7297, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [93/202], Loss: 0.8107, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [2/200], Step [96/202], Loss: 0.7088, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [2/200], Step [99/202], Loss: 0.7306, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [2/200], Step [102/202], Loss: 0.6097, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [105/202], Loss: 0.8272, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [2/200], Step [108/202], Loss: 0.6676, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [2/200], Step [111/202], Loss: 0.7488, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [2/200], Step [114/202], Loss: 0.6913, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [2/200], Step [117/202], Loss: 0.7073, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [120/202], Loss: 0.7201, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [2/200], Step [123/202], Loss: 0.8930, Accuracy: 43.75%, F1_Score: 0.44\n",
      "Epoch [2/200], Step [126/202], Loss: 0.6698, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [2/200], Step [129/202], Loss: 0.8921, Accuracy: 50.00%, F1_Score: 0.45\n",
      "Epoch [2/200], Step [132/202], Loss: 0.6257, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [2/200], Step [135/202], Loss: 0.5133, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [2/200], Step [138/202], Loss: 0.6926, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [141/202], Loss: 0.6581, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [2/200], Step [144/202], Loss: 0.6722, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [2/200], Step [147/202], Loss: 0.6446, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [150/202], Loss: 0.6486, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [153/202], Loss: 0.6752, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [2/200], Step [156/202], Loss: 0.6864, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [2/200], Step [159/202], Loss: 0.5818, Accuracy: 68.75%, F1_Score: 0.65\n",
      "Epoch [2/200], Step [162/202], Loss: 0.8539, Accuracy: 43.75%, F1_Score: 0.43\n",
      "Epoch [2/200], Step [165/202], Loss: 0.6600, Accuracy: 68.75%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [168/202], Loss: 0.5468, Accuracy: 68.75%, F1_Score: 0.67\n",
      "Epoch [2/200], Step [171/202], Loss: 0.7364, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [2/200], Step [174/202], Loss: 0.7923, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [2/200], Step [177/202], Loss: 0.8023, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [2/200], Step [180/202], Loss: 0.7033, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [2/200], Step [183/202], Loss: 0.8960, Accuracy: 43.75%, F1_Score: 0.43\n",
      "Epoch [2/200], Step [186/202], Loss: 0.7283, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [2/200], Step [189/202], Loss: 0.8613, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [2/200], Step [192/202], Loss: 0.7326, Accuracy: 43.75%, F1_Score: 0.42\n",
      "Epoch [2/200], Step [195/202], Loss: 0.7881, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [2/200], Step [198/202], Loss: 0.7036, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [2/200], Step [201/202], Loss: 0.6504, Accuracy: 62.50%, F1_Score: 0.61\n",
      "------------Epoch Finish------------\n",
      "Epoch [2/200], Accuracy: 58.49%, F1_Score: 0.57\n",
      "Start validation #2\n",
      "Validation #2  Accuracy: 60.19% F1_Score: 0.59 Average Loss: 0.6992\n",
      "Best performance at epoch: 2\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.38057849794859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [02:07<3:30:26, 63.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [3/200], Step [3/202], Loss: 0.7892, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [3/200], Step [6/202], Loss: 0.7438, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [3/200], Step [9/202], Loss: 0.7712, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [12/202], Loss: 0.5705, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [3/200], Step [15/202], Loss: 0.7817, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [3/200], Step [18/202], Loss: 0.6983, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [3/200], Step [21/202], Loss: 0.7005, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [24/202], Loss: 0.7051, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [3/200], Step [27/202], Loss: 0.7704, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [30/202], Loss: 0.7281, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [3/200], Step [33/202], Loss: 0.6089, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [36/202], Loss: 0.7134, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [3/200], Step [39/202], Loss: 0.7024, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [42/202], Loss: 0.6636, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [3/200], Step [45/202], Loss: 0.6877, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [3/200], Step [48/202], Loss: 0.7200, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [51/202], Loss: 0.5496, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [3/200], Step [54/202], Loss: 0.8011, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [3/200], Step [57/202], Loss: 0.6224, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [3/200], Step [60/202], Loss: 0.6675, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [63/202], Loss: 0.7797, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [3/200], Step [66/202], Loss: 0.6789, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [3/200], Step [69/202], Loss: 0.6225, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [72/202], Loss: 0.6560, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [3/200], Step [75/202], Loss: 0.6709, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [3/200], Step [78/202], Loss: 0.6442, Accuracy: 53.12%, F1_Score: 0.49\n",
      "Epoch [3/200], Step [81/202], Loss: 0.7113, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [3/200], Step [84/202], Loss: 0.7658, Accuracy: 53.12%, F1_Score: 0.47\n",
      "Epoch [3/200], Step [87/202], Loss: 0.8028, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [90/202], Loss: 0.5749, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [3/200], Step [93/202], Loss: 0.5414, Accuracy: 71.88%, F1_Score: 0.68\n",
      "Epoch [3/200], Step [96/202], Loss: 0.7273, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [99/202], Loss: 0.6485, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [3/200], Step [102/202], Loss: 0.7362, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [105/202], Loss: 0.6817, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [3/200], Step [108/202], Loss: 0.7735, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [3/200], Step [111/202], Loss: 0.7180, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [114/202], Loss: 0.7438, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [117/202], Loss: 0.6729, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [3/200], Step [120/202], Loss: 0.7574, Accuracy: 65.62%, F1_Score: 0.52\n",
      "Epoch [3/200], Step [123/202], Loss: 0.6520, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [3/200], Step [126/202], Loss: 0.7259, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [129/202], Loss: 0.7148, Accuracy: 53.12%, F1_Score: 0.51\n",
      "Epoch [3/200], Step [132/202], Loss: 0.7769, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [3/200], Step [135/202], Loss: 0.6826, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [3/200], Step [138/202], Loss: 0.7374, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [3/200], Step [141/202], Loss: 0.6576, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [144/202], Loss: 0.7173, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [3/200], Step [147/202], Loss: 0.6406, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [3/200], Step [150/202], Loss: 0.5688, Accuracy: 71.88%, F1_Score: 0.70\n",
      "Epoch [3/200], Step [153/202], Loss: 0.7314, Accuracy: 56.25%, F1_Score: 0.55\n",
      "Epoch [3/200], Step [156/202], Loss: 0.6879, Accuracy: 62.50%, F1_Score: 0.58\n",
      "Epoch [3/200], Step [159/202], Loss: 0.6642, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [3/200], Step [162/202], Loss: 0.5900, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [3/200], Step [165/202], Loss: 0.6099, Accuracy: 68.75%, F1_Score: 0.65\n",
      "Epoch [3/200], Step [168/202], Loss: 0.8231, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [3/200], Step [171/202], Loss: 0.6536, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [3/200], Step [174/202], Loss: 0.7574, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [3/200], Step [177/202], Loss: 0.7099, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [3/200], Step [180/202], Loss: 0.5805, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [3/200], Step [183/202], Loss: 0.5748, Accuracy: 71.88%, F1_Score: 0.71\n",
      "Epoch [3/200], Step [186/202], Loss: 0.5716, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [3/200], Step [189/202], Loss: 0.6394, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [3/200], Step [192/202], Loss: 1.0056, Accuracy: 34.38%, F1_Score: 0.31\n",
      "Epoch [3/200], Step [195/202], Loss: 0.6038, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [3/200], Step [198/202], Loss: 0.7695, Accuracy: 43.75%, F1_Score: 0.44\n",
      "Epoch [3/200], Step [201/202], Loss: 0.4595, Accuracy: 81.25%, F1_Score: 0.81\n",
      "------------Epoch Finish------------\n",
      "Epoch [3/200], Accuracy: 59.14%, F1_Score: 0.58\n",
      "Start validation #3\n",
      "Validation #3  Accuracy: 60.81% F1_Score: 0.60 Average Loss: 0.6909\n",
      "Best performance at epoch: 3\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.310537662007846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [03:11<3:29:15, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [4/200], Step [3/202], Loss: 0.5493, Accuracy: 65.62%, F1_Score: 0.63\n",
      "Epoch [4/200], Step [6/202], Loss: 0.7319, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [4/200], Step [9/202], Loss: 0.6672, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [4/200], Step [12/202], Loss: 0.6999, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [4/200], Step [15/202], Loss: 0.6997, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [4/200], Step [18/202], Loss: 0.7439, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [4/200], Step [21/202], Loss: 0.6563, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [4/200], Step [24/202], Loss: 0.7293, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [4/200], Step [27/202], Loss: 0.7207, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [4/200], Step [30/202], Loss: 0.6873, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [4/200], Step [33/202], Loss: 0.7891, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [4/200], Step [36/202], Loss: 0.5357, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [4/200], Step [39/202], Loss: 0.7607, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [4/200], Step [42/202], Loss: 0.7290, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [4/200], Step [45/202], Loss: 0.6968, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [4/200], Step [48/202], Loss: 0.7771, Accuracy: 56.25%, F1_Score: 0.55\n",
      "Epoch [4/200], Step [51/202], Loss: 0.6762, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [4/200], Step [54/202], Loss: 0.7083, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [57/202], Loss: 0.5991, Accuracy: 65.62%, F1_Score: 0.63\n",
      "Epoch [4/200], Step [60/202], Loss: 0.7103, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [4/200], Step [63/202], Loss: 0.7197, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [66/202], Loss: 0.7607, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [4/200], Step [69/202], Loss: 0.5917, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [4/200], Step [72/202], Loss: 0.6393, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [4/200], Step [75/202], Loss: 0.6786, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [4/200], Step [78/202], Loss: 0.7853, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [4/200], Step [81/202], Loss: 0.8612, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [4/200], Step [84/202], Loss: 0.6803, Accuracy: 68.75%, F1_Score: 0.58\n",
      "Epoch [4/200], Step [87/202], Loss: 0.8341, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [4/200], Step [90/202], Loss: 0.5267, Accuracy: 81.25%, F1_Score: 0.81\n",
      "Epoch [4/200], Step [93/202], Loss: 0.6123, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [4/200], Step [96/202], Loss: 0.6025, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [4/200], Step [99/202], Loss: 0.6722, Accuracy: 56.25%, F1_Score: 0.52\n",
      "Epoch [4/200], Step [102/202], Loss: 0.7098, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [105/202], Loss: 0.5725, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [4/200], Step [108/202], Loss: 0.6517, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [4/200], Step [111/202], Loss: 0.7372, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [4/200], Step [114/202], Loss: 0.8121, Accuracy: 40.62%, F1_Score: 0.41\n",
      "Epoch [4/200], Step [117/202], Loss: 0.6507, Accuracy: 62.50%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [120/202], Loss: 0.7459, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [4/200], Step [123/202], Loss: 0.6003, Accuracy: 71.88%, F1_Score: 0.69\n",
      "Epoch [4/200], Step [126/202], Loss: 0.7373, Accuracy: 56.25%, F1_Score: 0.49\n",
      "Epoch [4/200], Step [129/202], Loss: 0.7731, Accuracy: 46.88%, F1_Score: 0.44\n",
      "Epoch [4/200], Step [132/202], Loss: 0.5222, Accuracy: 75.00%, F1_Score: 0.74\n",
      "Epoch [4/200], Step [135/202], Loss: 0.6180, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [138/202], Loss: 0.5656, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [4/200], Step [141/202], Loss: 0.6814, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [4/200], Step [144/202], Loss: 0.5403, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [4/200], Step [147/202], Loss: 0.7762, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [4/200], Step [150/202], Loss: 0.7193, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [4/200], Step [153/202], Loss: 0.6278, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [4/200], Step [156/202], Loss: 0.6612, Accuracy: 53.12%, F1_Score: 0.47\n",
      "Epoch [4/200], Step [159/202], Loss: 0.6485, Accuracy: 56.25%, F1_Score: 0.46\n",
      "Epoch [4/200], Step [162/202], Loss: 0.6041, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [4/200], Step [165/202], Loss: 0.6669, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [4/200], Step [168/202], Loss: 0.6539, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [4/200], Step [171/202], Loss: 0.8000, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [4/200], Step [174/202], Loss: 0.8179, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [4/200], Step [177/202], Loss: 0.8488, Accuracy: 43.75%, F1_Score: 0.44\n",
      "Epoch [4/200], Step [180/202], Loss: 0.5919, Accuracy: 65.62%, F1_Score: 0.64\n",
      "Epoch [4/200], Step [183/202], Loss: 0.8056, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [4/200], Step [186/202], Loss: 0.7585, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [4/200], Step [189/202], Loss: 0.6338, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [4/200], Step [192/202], Loss: 0.6512, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [4/200], Step [195/202], Loss: 0.5161, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [4/200], Step [198/202], Loss: 0.7476, Accuracy: 46.88%, F1_Score: 0.42\n",
      "Epoch [4/200], Step [201/202], Loss: 0.6675, Accuracy: 59.38%, F1_Score: 0.58\n",
      "------------Epoch Finish------------\n",
      "Epoch [4/200], Accuracy: 59.33%, F1_Score: 0.58\n",
      "Start validation #4\n",
      "Validation #4  Accuracy: 61.38% F1_Score: 0.60 Average Loss: 0.6829\n",
      "Best performance at epoch: 4\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.44313228299143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [04:15<3:28:23, 63.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [5/200], Step [3/202], Loss: 0.5457, Accuracy: 81.25%, F1_Score: 0.81\n",
      "Epoch [5/200], Step [6/202], Loss: 0.5884, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [9/202], Loss: 0.7868, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [5/200], Step [12/202], Loss: 0.7887, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [15/202], Loss: 0.5705, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [5/200], Step [18/202], Loss: 0.7993, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [21/202], Loss: 0.7230, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [24/202], Loss: 0.6819, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [27/202], Loss: 0.6969, Accuracy: 65.62%, F1_Score: 0.64\n",
      "Epoch [5/200], Step [30/202], Loss: 0.6679, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [33/202], Loss: 0.7379, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [36/202], Loss: 0.8069, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [39/202], Loss: 0.6551, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [42/202], Loss: 0.6994, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [5/200], Step [45/202], Loss: 0.7343, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [5/200], Step [48/202], Loss: 0.6315, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [51/202], Loss: 0.5740, Accuracy: 71.88%, F1_Score: 0.69\n",
      "Epoch [5/200], Step [54/202], Loss: 0.7623, Accuracy: 50.00%, F1_Score: 0.45\n",
      "Epoch [5/200], Step [57/202], Loss: 0.7899, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [60/202], Loss: 0.7813, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [63/202], Loss: 0.5683, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [5/200], Step [66/202], Loss: 0.6147, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [69/202], Loss: 0.5364, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [5/200], Step [72/202], Loss: 0.7069, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [5/200], Step [75/202], Loss: 0.6522, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [78/202], Loss: 0.6732, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [5/200], Step [81/202], Loss: 0.7386, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [84/202], Loss: 0.5475, Accuracy: 68.75%, F1_Score: 0.65\n",
      "Epoch [5/200], Step [87/202], Loss: 0.6271, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [5/200], Step [90/202], Loss: 0.7300, Accuracy: 53.12%, F1_Score: 0.51\n",
      "Epoch [5/200], Step [93/202], Loss: 0.8041, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [96/202], Loss: 0.7613, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [5/200], Step [99/202], Loss: 0.6725, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [102/202], Loss: 0.8585, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [5/200], Step [105/202], Loss: 0.7792, Accuracy: 46.88%, F1_Score: 0.44\n",
      "Epoch [5/200], Step [108/202], Loss: 0.5957, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [5/200], Step [111/202], Loss: 0.7510, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [114/202], Loss: 0.6698, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [117/202], Loss: 0.6100, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [120/202], Loss: 0.6948, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [123/202], Loss: 0.7376, Accuracy: 46.88%, F1_Score: 0.47\n",
      "Epoch [5/200], Step [126/202], Loss: 0.8781, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [5/200], Step [129/202], Loss: 0.7173, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [5/200], Step [132/202], Loss: 0.6471, Accuracy: 62.50%, F1_Score: 0.60\n",
      "Epoch [5/200], Step [135/202], Loss: 0.6196, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [138/202], Loss: 0.6740, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [5/200], Step [141/202], Loss: 0.6097, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [144/202], Loss: 0.6398, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [5/200], Step [147/202], Loss: 0.7588, Accuracy: 53.12%, F1_Score: 0.52\n",
      "Epoch [5/200], Step [150/202], Loss: 0.7960, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [5/200], Step [153/202], Loss: 0.6374, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [156/202], Loss: 0.6304, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [159/202], Loss: 0.4864, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [5/200], Step [162/202], Loss: 0.6564, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [5/200], Step [165/202], Loss: 0.6321, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [168/202], Loss: 0.6189, Accuracy: 46.88%, F1_Score: 0.47\n",
      "Epoch [5/200], Step [171/202], Loss: 0.5550, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [5/200], Step [174/202], Loss: 0.6060, Accuracy: 65.62%, F1_Score: 0.63\n",
      "Epoch [5/200], Step [177/202], Loss: 0.6238, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [5/200], Step [180/202], Loss: 0.7834, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [183/202], Loss: 0.7352, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [5/200], Step [186/202], Loss: 0.6008, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [5/200], Step [189/202], Loss: 0.7918, Accuracy: 50.00%, F1_Score: 0.45\n",
      "Epoch [5/200], Step [192/202], Loss: 0.8770, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [195/202], Loss: 0.6912, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [5/200], Step [198/202], Loss: 0.5805, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [5/200], Step [201/202], Loss: 0.7329, Accuracy: 62.50%, F1_Score: 0.62\n",
      "------------Epoch Finish------------\n",
      "Epoch [5/200], Accuracy: 60.13%, F1_Score: 0.59\n",
      "Start validation #5\n",
      "Validation #5  Accuracy: 61.88% F1_Score: 0.61 Average Loss: 0.6755\n",
      "Best performance at epoch: 5\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.331923994002864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [05:18<3:27:16, 63.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [6/200], Step [3/202], Loss: 0.5979, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [6/200], Step [6/202], Loss: 0.6298, Accuracy: 71.88%, F1_Score: 0.70\n",
      "Epoch [6/200], Step [9/202], Loss: 0.6605, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [6/200], Step [12/202], Loss: 0.7307, Accuracy: 46.88%, F1_Score: 0.42\n",
      "Epoch [6/200], Step [15/202], Loss: 0.6502, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [6/200], Step [18/202], Loss: 0.5016, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [6/200], Step [21/202], Loss: 0.6695, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [6/200], Step [24/202], Loss: 0.7426, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [27/202], Loss: 0.8966, Accuracy: 43.75%, F1_Score: 0.43\n",
      "Epoch [6/200], Step [30/202], Loss: 0.7206, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [6/200], Step [33/202], Loss: 0.7231, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [6/200], Step [36/202], Loss: 0.6414, Accuracy: 56.25%, F1_Score: 0.52\n",
      "Epoch [6/200], Step [39/202], Loss: 0.7074, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [42/202], Loss: 0.6219, Accuracy: 62.50%, F1_Score: 0.61\n",
      "Epoch [6/200], Step [45/202], Loss: 0.7184, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [6/200], Step [48/202], Loss: 0.5467, Accuracy: 71.88%, F1_Score: 0.70\n",
      "Epoch [6/200], Step [51/202], Loss: 0.6231, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [6/200], Step [54/202], Loss: 0.7148, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [6/200], Step [57/202], Loss: 0.5443, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [6/200], Step [60/202], Loss: 0.5570, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [6/200], Step [63/202], Loss: 0.7535, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [6/200], Step [66/202], Loss: 0.6524, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [69/202], Loss: 0.7395, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [6/200], Step [72/202], Loss: 0.5637, Accuracy: 78.12%, F1_Score: 0.78\n",
      "Epoch [6/200], Step [75/202], Loss: 0.6720, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [6/200], Step [78/202], Loss: 0.8100, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [81/202], Loss: 0.7896, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [6/200], Step [84/202], Loss: 0.7870, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [6/200], Step [87/202], Loss: 0.7535, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [6/200], Step [90/202], Loss: 0.7284, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [93/202], Loss: 0.5420, Accuracy: 71.88%, F1_Score: 0.71\n",
      "Epoch [6/200], Step [96/202], Loss: 0.6670, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [6/200], Step [99/202], Loss: 0.7254, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [102/202], Loss: 0.7724, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [6/200], Step [105/202], Loss: 0.7685, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [108/202], Loss: 0.7904, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [6/200], Step [111/202], Loss: 0.6794, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [6/200], Step [114/202], Loss: 0.6400, Accuracy: 59.38%, F1_Score: 0.54\n",
      "Epoch [6/200], Step [117/202], Loss: 0.7233, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [120/202], Loss: 0.6346, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [6/200], Step [123/202], Loss: 0.7154, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [126/202], Loss: 0.7473, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [129/202], Loss: 0.7256, Accuracy: 50.00%, F1_Score: 0.48\n",
      "Epoch [6/200], Step [132/202], Loss: 0.8473, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [135/202], Loss: 0.6431, Accuracy: 56.25%, F1_Score: 0.56\n",
      "Epoch [6/200], Step [138/202], Loss: 0.7218, Accuracy: 50.00%, F1_Score: 0.49\n",
      "Epoch [6/200], Step [141/202], Loss: 0.6729, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [6/200], Step [144/202], Loss: 0.7663, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [6/200], Step [147/202], Loss: 0.6523, Accuracy: 71.88%, F1_Score: 0.70\n",
      "Epoch [6/200], Step [150/202], Loss: 0.5617, Accuracy: 75.00%, F1_Score: 0.73\n",
      "Epoch [6/200], Step [153/202], Loss: 0.6991, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [6/200], Step [156/202], Loss: 0.5927, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [6/200], Step [159/202], Loss: 0.6426, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [6/200], Step [162/202], Loss: 0.6445, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [165/202], Loss: 0.6354, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [168/202], Loss: 0.5842, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [6/200], Step [171/202], Loss: 0.6844, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [6/200], Step [174/202], Loss: 0.7300, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [177/202], Loss: 0.5727, Accuracy: 62.50%, F1_Score: 0.60\n",
      "Epoch [6/200], Step [180/202], Loss: 0.7042, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [6/200], Step [183/202], Loss: 0.6605, Accuracy: 68.75%, F1_Score: 0.68\n",
      "Epoch [6/200], Step [186/202], Loss: 0.7850, Accuracy: 46.88%, F1_Score: 0.46\n",
      "Epoch [6/200], Step [189/202], Loss: 0.6070, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [6/200], Step [192/202], Loss: 0.7856, Accuracy: 43.75%, F1_Score: 0.42\n",
      "Epoch [6/200], Step [195/202], Loss: 0.6051, Accuracy: 71.88%, F1_Score: 0.72\n",
      "Epoch [6/200], Step [198/202], Loss: 0.6221, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [6/200], Step [201/202], Loss: 0.5555, Accuracy: 71.88%, F1_Score: 0.72\n",
      "------------Epoch Finish------------\n",
      "Epoch [6/200], Accuracy: 60.78%, F1_Score: 0.60\n",
      "Start validation #6\n",
      "Validation #6  Accuracy: 62.31% F1_Score: 0.62 Average Loss: 0.6683\n",
      "Best performance at epoch: 6\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 61.36755687801633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [06:22<3:26:11, 63.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [7/200], Step [3/202], Loss: 0.6753, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [7/200], Step [6/202], Loss: 0.6946, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [7/200], Step [9/202], Loss: 0.6062, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [7/200], Step [12/202], Loss: 0.6932, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [7/200], Step [15/202], Loss: 0.7053, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [7/200], Step [18/202], Loss: 0.6083, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [7/200], Step [21/202], Loss: 0.9444, Accuracy: 50.00%, F1_Score: 0.50\n",
      "Epoch [7/200], Step [24/202], Loss: 0.6710, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [7/200], Step [27/202], Loss: 0.6694, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [7/200], Step [30/202], Loss: 0.7086, Accuracy: 59.38%, F1_Score: 0.58\n",
      "Epoch [7/200], Step [33/202], Loss: 0.8056, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [7/200], Step [36/202], Loss: 0.6782, Accuracy: 59.38%, F1_Score: 0.59\n",
      "Epoch [7/200], Step [39/202], Loss: 0.6728, Accuracy: 65.62%, F1_Score: 0.66\n",
      "Epoch [7/200], Step [42/202], Loss: 0.6850, Accuracy: 59.38%, F1_Score: 0.56\n",
      "Epoch [7/200], Step [45/202], Loss: 0.5609, Accuracy: 65.62%, F1_Score: 0.65\n",
      "Epoch [7/200], Step [48/202], Loss: 0.8863, Accuracy: 46.88%, F1_Score: 0.47\n",
      "Epoch [7/200], Step [51/202], Loss: 0.6514, Accuracy: 62.50%, F1_Score: 0.60\n",
      "Epoch [7/200], Step [54/202], Loss: 0.7150, Accuracy: 56.25%, F1_Score: 0.53\n",
      "Epoch [7/200], Step [57/202], Loss: 0.8358, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [7/200], Step [60/202], Loss: 0.6021, Accuracy: 71.88%, F1_Score: 0.70\n",
      "Epoch [7/200], Step [63/202], Loss: 0.6051, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [7/200], Step [66/202], Loss: 0.5470, Accuracy: 75.00%, F1_Score: 0.75\n",
      "Epoch [7/200], Step [69/202], Loss: 0.7059, Accuracy: 53.12%, F1_Score: 0.53\n",
      "Epoch [7/200], Step [72/202], Loss: 0.6342, Accuracy: 59.38%, F1_Score: 0.54\n",
      "Epoch [7/200], Step [75/202], Loss: 0.6155, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [7/200], Step [78/202], Loss: 0.6688, Accuracy: 59.38%, F1_Score: 0.57\n",
      "Epoch [7/200], Step [81/202], Loss: 0.7327, Accuracy: 62.50%, F1_Score: 0.62\n",
      "Epoch [7/200], Step [84/202], Loss: 0.5970, Accuracy: 71.88%, F1_Score: 0.69\n",
      "Epoch [7/200], Step [87/202], Loss: 0.7023, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [7/200], Step [90/202], Loss: 0.5379, Accuracy: 81.25%, F1_Score: 0.81\n",
      "Epoch [7/200], Step [93/202], Loss: 0.5999, Accuracy: 68.75%, F1_Score: 0.69\n",
      "Epoch [7/200], Step [96/202], Loss: 0.7598, Accuracy: 50.00%, F1_Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, model, train_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6573b-fbad-4ab9-b53b-1458321a8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/model/best_model.pt'\n",
    "checkpoint = torch.load(model_path,map_location=device)\n",
    "state_dict = checkpoint['net']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f3d18-5ddd-437c-a9af-75cdaafeb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in test_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submit_dir = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/submit'\n",
    "submission.to_csv(os.path.join(submit_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49871ff6-169a-44c3-88b1-a5fdf7176e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
