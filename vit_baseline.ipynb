{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496610b8-dc45-4f2e-b611-c82ca0ba9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69951b-6bdc-467d-b82a-48c1886f6e5a",
   "metadata": {},
   "source": [
    "# 시드 및 모델의 기본적인 파라미터 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61a476d-24fc-4ef7-890f-e5972ebadfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "seed_everything(42)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd987-7c9e-4f54-971b-41e64888c74c",
   "metadata": {},
   "source": [
    "# GPU 확인 및 device에 사용할 gpu 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762454ac-07d9-4704-ae04-bb309914f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1\n",
      "GPU 사용 가능 여부: True\n"
     ]
    }
   ],
   "source": [
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7155fc-26f1-40be-ab29-d7de927c8bf9",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6289b8ce-91e1-471b-96fe-1132efc0b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeperateDataset(Dataset): # 각 목표별 데이터셋 만들기\n",
    "    def __init__(self, df, transform, target):\n",
    "        self.df = df\n",
    "        self.img_paths = self.df['path'].tolist()\n",
    "        self.labels = self.df[target].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b160f-56f6-450f-8c5f-54f427c5739a",
   "metadata": {},
   "source": [
    "# transform 만들기\n",
    "### 아래 부분은 3x384x384 할지 3x224x224할지 조건에 따라 선택해서 사용하시면 됩니다.\n",
    "### 각각 resize 후에 80퍼센트만 남도록 crop을 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4e8711-2bdd-48c1-a1e9-46eab25730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.Resize((280,280)),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.RandomRotation(5),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'test': transforms.Compose([\n",
    "#         transforms.Resize((280,280)),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# 아래 영역을 마우스로 지정하고, 컨트롤키 + '/' 눌러서 주석 제거\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((480,480)),\n",
    "        transforms.CenterCrop(384),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((480,480)),\n",
    "        transforms.CenterCrop(384),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2a827-8b24-4152-bb5b-a0157fc46ebe",
   "metadata": {},
   "source": [
    "# 학습할 데이터 불러오기\n",
    "### 이 아래 부분은 실험 조건에 따라서 주석처리하면서 돌리면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647ac103-89a5-4987-867a-c434a59bd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5:1:1\n",
    "#df = pd.read_csv(\"/opt/ml/code/total.csv\")\n",
    "\n",
    "# 1:1:1\n",
    "df = pd.read_csv(\"/opt/ml/code/total_111.csv\", index_col=None)\n",
    "list_columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c90afeb-0fe2-4909-b3ec-f2ed8a52ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maskOX</th>\n",
       "      <th>maskGB</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/train/images/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>/opt/ml/input/data/train/images/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>/opt/ml/input/data/train/images/006957_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>/opt/ml/input/data/train/images/006957_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  maskOX  maskGB  class  \\\n",
       "0          1    1       1     1.0      4   \n",
       "1          1    1       0     NaN     16   \n",
       "2          1    1       1     0.0     10   \n",
       "3          1    1       1     1.0      4   \n",
       "4          1    1       0     NaN     16   \n",
       "...      ...  ...     ...     ...    ...   \n",
       "8095       0    0       0     NaN     12   \n",
       "8096       0    0       1     0.0      6   \n",
       "8097       0    0       1     1.0      0   \n",
       "8098       0    0       0     NaN     12   \n",
       "8099       0    0       1     0.0      6   \n",
       "\n",
       "                                                   path  \n",
       "0     /opt/ml/input/data/train/images/000001_female_...  \n",
       "1     /opt/ml/input/data/train/images/000001_female_...  \n",
       "2     /opt/ml/input/data/train/images/000001_female_...  \n",
       "3     /opt/ml/input/data/train/images/000002_female_...  \n",
       "4     /opt/ml/input/data/train/images/000002_female_...  \n",
       "...                                                 ...  \n",
       "8095  /opt/ml/input/data/train/images/006957_male_As...  \n",
       "8096  /opt/ml/input/data/train/images/006957_male_As...  \n",
       "8097  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "8098  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "8099  /opt/ml/input/data/train/images/006959_male_As...  \n",
       "\n",
       "[8100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b983a77d-968a-44d8-8c54-d9ee56c33b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval/'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec3040-2721-4718-aabb-95c5142a9615",
   "metadata": {},
   "source": [
    "### 만들 타겟을 아래에 적어주세요 (gender/age/maskOX/maskGB/class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11ac1e8-1ec2-41d7-85e4-9183fd525a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target =\"class\"\n",
    "list_columns.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062fed46-514f-48c6-8559-dee94cefe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[list_columns], df[target], test_size=0.2, stratify=df[target], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539259c1-5d81-4826-a3fe-f7f5ac6c0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c503b5f4-b898-4b51-973f-8234d21089bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SeperateDataset(train_df, transform=data_transforms['train'], target=target)\n",
    "val_data = SeperateDataset(test_df, transform=data_transforms['test'], target=target)\n",
    "test_data = TestDataset(image_paths, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2f7306-d2b6-4765-960c-e097c261b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def train(num_epochs, model, data_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    total_start_time = timeit.default_timer()\n",
    "    best_loss = 9999999\n",
    "    best_test_accuracy = 0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_f1 = 0\n",
    "        running_acc = 0\n",
    "        print('Epoch start..')\n",
    "        epoch_start_time = timeit.default_timer()\n",
    "        for i, (imgs, labels) in enumerate(data_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            ## 코드 시작 ##\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()         \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy = (labels == argmax).float().mean()\n",
    "            \n",
    "            f1 = f1_score(labels.cpu().numpy(), argmax.cpu().numpy(), average='macro')\n",
    "            epoch_f1 += f1\n",
    "            running_acc += accuracy\n",
    "            if (i+1) % 3 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%, F1_Score: {:.2f}'.format(\n",
    "                    epoch+1, num_epochs, i+1, len(data_loader), loss.item(), accuracy.item() * 100, f1))\n",
    "        print(\"------------Epoch Finish------------\")\n",
    "        print('Epoch [{}/{}], Accuracy: {:.2f}%, F1_Score: {:.2f}'.format(\n",
    "                    epoch+1, num_epochs, running_acc.item()/(i+1) * 100,epoch_f1/(i+1)))\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)\n",
    "        epoch_end_time = timeit.default_timer()\n",
    "        print(\"Epoch end..\")\n",
    "        print(f\"epoch time : {epoch_end_time-epoch_start_time}\")\n",
    "        epoch_acc = running_acc / (i+1)\n",
    "        \n",
    "        if best_test_accuracy < epoch_acc:\n",
    "            best_test_accuracy = epoch_acc\n",
    "            save_model(model, saved_dir)\n",
    "            early_stop_point = 0\n",
    "        else:\n",
    "            early_stop_point += 1\n",
    "        if early_stop_point == 3:\n",
    "            print('early_stopped')\n",
    "            break\n",
    "    print('End training..')\n",
    "    total_end_time = timeit.default_timer()\n",
    "    print(f\"total time : {total_end_time-total_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6500ffe5-8611-4bb5-b677-079864700979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch) )\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        epoch_f1 = 0\n",
    "        for i, (imgs, labels) in enumerate(data_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            ## 코드 시작 ##\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            ## 코드 종료 ##\n",
    "            total += imgs.size(0)\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item()\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            epoch_f1 += f1_score(labels.cpu().numpy(), argmax.cpu().numpy(), average='macro')\n",
    "        avrg_loss = total_loss / cnt\n",
    "        avrg_f1 = epoch_f1 / cnt\n",
    "        print('Validation #{}  Accuracy: {:.2f}% F1_Score: {:.2f} Average Loss: {:.4f}'.format(epoch, correct / total * 100,avrg_f1 ,avrg_loss))\n",
    "    model.train()\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd7ad5a3-e669-4dc7-b8b2-31e331232967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir, file_name='best_modelvit.pt'):\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    check_point = {\n",
    "        'net': model.state_dict()\n",
    "    }\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(check_point,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6601b89-001e-443b-b3f4-f0f869e458f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d4f22c-5938-4cea-8363-91b69567f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "class ViTLarge32_384(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "\n",
    "        super(ViTLarge32_384, self).__init__()\n",
    "\n",
    "        self.model = timm.create_model(\"vit_large_patch32_384\", pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf2dac7-3f9a-40dc-86aa-c9bf0ab7259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target에 따라서 n_classes 정하면 된다.\n",
    "model = ViTLarge32_384(n_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab078195-ffce-4e8a-b430-164d8dab9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "saved_dir = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/model'\n",
    "val_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab2de743-e772-4d9c-8259-698147230e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 1024, 12, 12]       3,146,752\n",
      "          Identity-2            [32, 144, 1024]               0\n",
      "        PatchEmbed-3            [32, 144, 1024]               0\n",
      "           Dropout-4            [32, 145, 1024]               0\n",
      "         LayerNorm-5            [32, 145, 1024]           2,048\n",
      "            Linear-6            [32, 145, 3072]       3,148,800\n",
      "           Dropout-7         [32, 16, 145, 145]               0\n",
      "            Linear-8            [32, 145, 1024]       1,049,600\n",
      "           Dropout-9            [32, 145, 1024]               0\n",
      "        Attention-10            [32, 145, 1024]               0\n",
      "         Identity-11            [32, 145, 1024]               0\n",
      "        LayerNorm-12            [32, 145, 1024]           2,048\n",
      "           Linear-13            [32, 145, 4096]       4,198,400\n",
      "             GELU-14            [32, 145, 4096]               0\n",
      "          Dropout-15            [32, 145, 4096]               0\n",
      "           Linear-16            [32, 145, 1024]       4,195,328\n",
      "          Dropout-17            [32, 145, 1024]               0\n",
      "              Mlp-18            [32, 145, 1024]               0\n",
      "         Identity-19            [32, 145, 1024]               0\n",
      "            Block-20            [32, 145, 1024]               0\n",
      "        LayerNorm-21            [32, 145, 1024]           2,048\n",
      "           Linear-22            [32, 145, 3072]       3,148,800\n",
      "          Dropout-23         [32, 16, 145, 145]               0\n",
      "           Linear-24            [32, 145, 1024]       1,049,600\n",
      "          Dropout-25            [32, 145, 1024]               0\n",
      "        Attention-26            [32, 145, 1024]               0\n",
      "         Identity-27            [32, 145, 1024]               0\n",
      "        LayerNorm-28            [32, 145, 1024]           2,048\n",
      "           Linear-29            [32, 145, 4096]       4,198,400\n",
      "             GELU-30            [32, 145, 4096]               0\n",
      "          Dropout-31            [32, 145, 4096]               0\n",
      "           Linear-32            [32, 145, 1024]       4,195,328\n",
      "          Dropout-33            [32, 145, 1024]               0\n",
      "              Mlp-34            [32, 145, 1024]               0\n",
      "         Identity-35            [32, 145, 1024]               0\n",
      "            Block-36            [32, 145, 1024]               0\n",
      "        LayerNorm-37            [32, 145, 1024]           2,048\n",
      "           Linear-38            [32, 145, 3072]       3,148,800\n",
      "          Dropout-39         [32, 16, 145, 145]               0\n",
      "           Linear-40            [32, 145, 1024]       1,049,600\n",
      "          Dropout-41            [32, 145, 1024]               0\n",
      "        Attention-42            [32, 145, 1024]               0\n",
      "         Identity-43            [32, 145, 1024]               0\n",
      "        LayerNorm-44            [32, 145, 1024]           2,048\n",
      "           Linear-45            [32, 145, 4096]       4,198,400\n",
      "             GELU-46            [32, 145, 4096]               0\n",
      "          Dropout-47            [32, 145, 4096]               0\n",
      "           Linear-48            [32, 145, 1024]       4,195,328\n",
      "          Dropout-49            [32, 145, 1024]               0\n",
      "              Mlp-50            [32, 145, 1024]               0\n",
      "         Identity-51            [32, 145, 1024]               0\n",
      "            Block-52            [32, 145, 1024]               0\n",
      "        LayerNorm-53            [32, 145, 1024]           2,048\n",
      "           Linear-54            [32, 145, 3072]       3,148,800\n",
      "          Dropout-55         [32, 16, 145, 145]               0\n",
      "           Linear-56            [32, 145, 1024]       1,049,600\n",
      "          Dropout-57            [32, 145, 1024]               0\n",
      "        Attention-58            [32, 145, 1024]               0\n",
      "         Identity-59            [32, 145, 1024]               0\n",
      "        LayerNorm-60            [32, 145, 1024]           2,048\n",
      "           Linear-61            [32, 145, 4096]       4,198,400\n",
      "             GELU-62            [32, 145, 4096]               0\n",
      "          Dropout-63            [32, 145, 4096]               0\n",
      "           Linear-64            [32, 145, 1024]       4,195,328\n",
      "          Dropout-65            [32, 145, 1024]               0\n",
      "              Mlp-66            [32, 145, 1024]               0\n",
      "         Identity-67            [32, 145, 1024]               0\n",
      "            Block-68            [32, 145, 1024]               0\n",
      "        LayerNorm-69            [32, 145, 1024]           2,048\n",
      "           Linear-70            [32, 145, 3072]       3,148,800\n",
      "          Dropout-71         [32, 16, 145, 145]               0\n",
      "           Linear-72            [32, 145, 1024]       1,049,600\n",
      "          Dropout-73            [32, 145, 1024]               0\n",
      "        Attention-74            [32, 145, 1024]               0\n",
      "         Identity-75            [32, 145, 1024]               0\n",
      "        LayerNorm-76            [32, 145, 1024]           2,048\n",
      "           Linear-77            [32, 145, 4096]       4,198,400\n",
      "             GELU-78            [32, 145, 4096]               0\n",
      "          Dropout-79            [32, 145, 4096]               0\n",
      "           Linear-80            [32, 145, 1024]       4,195,328\n",
      "          Dropout-81            [32, 145, 1024]               0\n",
      "              Mlp-82            [32, 145, 1024]               0\n",
      "         Identity-83            [32, 145, 1024]               0\n",
      "            Block-84            [32, 145, 1024]               0\n",
      "        LayerNorm-85            [32, 145, 1024]           2,048\n",
      "           Linear-86            [32, 145, 3072]       3,148,800\n",
      "          Dropout-87         [32, 16, 145, 145]               0\n",
      "           Linear-88            [32, 145, 1024]       1,049,600\n",
      "          Dropout-89            [32, 145, 1024]               0\n",
      "        Attention-90            [32, 145, 1024]               0\n",
      "         Identity-91            [32, 145, 1024]               0\n",
      "        LayerNorm-92            [32, 145, 1024]           2,048\n",
      "           Linear-93            [32, 145, 4096]       4,198,400\n",
      "             GELU-94            [32, 145, 4096]               0\n",
      "          Dropout-95            [32, 145, 4096]               0\n",
      "           Linear-96            [32, 145, 1024]       4,195,328\n",
      "          Dropout-97            [32, 145, 1024]               0\n",
      "              Mlp-98            [32, 145, 1024]               0\n",
      "         Identity-99            [32, 145, 1024]               0\n",
      "           Block-100            [32, 145, 1024]               0\n",
      "       LayerNorm-101            [32, 145, 1024]           2,048\n",
      "          Linear-102            [32, 145, 3072]       3,148,800\n",
      "         Dropout-103         [32, 16, 145, 145]               0\n",
      "          Linear-104            [32, 145, 1024]       1,049,600\n",
      "         Dropout-105            [32, 145, 1024]               0\n",
      "       Attention-106            [32, 145, 1024]               0\n",
      "        Identity-107            [32, 145, 1024]               0\n",
      "       LayerNorm-108            [32, 145, 1024]           2,048\n",
      "          Linear-109            [32, 145, 4096]       4,198,400\n",
      "            GELU-110            [32, 145, 4096]               0\n",
      "         Dropout-111            [32, 145, 4096]               0\n",
      "          Linear-112            [32, 145, 1024]       4,195,328\n",
      "         Dropout-113            [32, 145, 1024]               0\n",
      "             Mlp-114            [32, 145, 1024]               0\n",
      "        Identity-115            [32, 145, 1024]               0\n",
      "           Block-116            [32, 145, 1024]               0\n",
      "       LayerNorm-117            [32, 145, 1024]           2,048\n",
      "          Linear-118            [32, 145, 3072]       3,148,800\n",
      "         Dropout-119         [32, 16, 145, 145]               0\n",
      "          Linear-120            [32, 145, 1024]       1,049,600\n",
      "         Dropout-121            [32, 145, 1024]               0\n",
      "       Attention-122            [32, 145, 1024]               0\n",
      "        Identity-123            [32, 145, 1024]               0\n",
      "       LayerNorm-124            [32, 145, 1024]           2,048\n",
      "          Linear-125            [32, 145, 4096]       4,198,400\n",
      "            GELU-126            [32, 145, 4096]               0\n",
      "         Dropout-127            [32, 145, 4096]               0\n",
      "          Linear-128            [32, 145, 1024]       4,195,328\n",
      "         Dropout-129            [32, 145, 1024]               0\n",
      "             Mlp-130            [32, 145, 1024]               0\n",
      "        Identity-131            [32, 145, 1024]               0\n",
      "           Block-132            [32, 145, 1024]               0\n",
      "       LayerNorm-133            [32, 145, 1024]           2,048\n",
      "          Linear-134            [32, 145, 3072]       3,148,800\n",
      "         Dropout-135         [32, 16, 145, 145]               0\n",
      "          Linear-136            [32, 145, 1024]       1,049,600\n",
      "         Dropout-137            [32, 145, 1024]               0\n",
      "       Attention-138            [32, 145, 1024]               0\n",
      "        Identity-139            [32, 145, 1024]               0\n",
      "       LayerNorm-140            [32, 145, 1024]           2,048\n",
      "          Linear-141            [32, 145, 4096]       4,198,400\n",
      "            GELU-142            [32, 145, 4096]               0\n",
      "         Dropout-143            [32, 145, 4096]               0\n",
      "          Linear-144            [32, 145, 1024]       4,195,328\n",
      "         Dropout-145            [32, 145, 1024]               0\n",
      "             Mlp-146            [32, 145, 1024]               0\n",
      "        Identity-147            [32, 145, 1024]               0\n",
      "           Block-148            [32, 145, 1024]               0\n",
      "       LayerNorm-149            [32, 145, 1024]           2,048\n",
      "          Linear-150            [32, 145, 3072]       3,148,800\n",
      "         Dropout-151         [32, 16, 145, 145]               0\n",
      "          Linear-152            [32, 145, 1024]       1,049,600\n",
      "         Dropout-153            [32, 145, 1024]               0\n",
      "       Attention-154            [32, 145, 1024]               0\n",
      "        Identity-155            [32, 145, 1024]               0\n",
      "       LayerNorm-156            [32, 145, 1024]           2,048\n",
      "          Linear-157            [32, 145, 4096]       4,198,400\n",
      "            GELU-158            [32, 145, 4096]               0\n",
      "         Dropout-159            [32, 145, 4096]               0\n",
      "          Linear-160            [32, 145, 1024]       4,195,328\n",
      "         Dropout-161            [32, 145, 1024]               0\n",
      "             Mlp-162            [32, 145, 1024]               0\n",
      "        Identity-163            [32, 145, 1024]               0\n",
      "           Block-164            [32, 145, 1024]               0\n",
      "       LayerNorm-165            [32, 145, 1024]           2,048\n",
      "          Linear-166            [32, 145, 3072]       3,148,800\n",
      "         Dropout-167         [32, 16, 145, 145]               0\n",
      "          Linear-168            [32, 145, 1024]       1,049,600\n",
      "         Dropout-169            [32, 145, 1024]               0\n",
      "       Attention-170            [32, 145, 1024]               0\n",
      "        Identity-171            [32, 145, 1024]               0\n",
      "       LayerNorm-172            [32, 145, 1024]           2,048\n",
      "          Linear-173            [32, 145, 4096]       4,198,400\n",
      "            GELU-174            [32, 145, 4096]               0\n",
      "         Dropout-175            [32, 145, 4096]               0\n",
      "          Linear-176            [32, 145, 1024]       4,195,328\n",
      "         Dropout-177            [32, 145, 1024]               0\n",
      "             Mlp-178            [32, 145, 1024]               0\n",
      "        Identity-179            [32, 145, 1024]               0\n",
      "           Block-180            [32, 145, 1024]               0\n",
      "       LayerNorm-181            [32, 145, 1024]           2,048\n",
      "          Linear-182            [32, 145, 3072]       3,148,800\n",
      "         Dropout-183         [32, 16, 145, 145]               0\n",
      "          Linear-184            [32, 145, 1024]       1,049,600\n",
      "         Dropout-185            [32, 145, 1024]               0\n",
      "       Attention-186            [32, 145, 1024]               0\n",
      "        Identity-187            [32, 145, 1024]               0\n",
      "       LayerNorm-188            [32, 145, 1024]           2,048\n",
      "          Linear-189            [32, 145, 4096]       4,198,400\n",
      "            GELU-190            [32, 145, 4096]               0\n",
      "         Dropout-191            [32, 145, 4096]               0\n",
      "          Linear-192            [32, 145, 1024]       4,195,328\n",
      "         Dropout-193            [32, 145, 1024]               0\n",
      "             Mlp-194            [32, 145, 1024]               0\n",
      "        Identity-195            [32, 145, 1024]               0\n",
      "           Block-196            [32, 145, 1024]               0\n",
      "       LayerNorm-197            [32, 145, 1024]           2,048\n",
      "          Linear-198            [32, 145, 3072]       3,148,800\n",
      "         Dropout-199         [32, 16, 145, 145]               0\n",
      "          Linear-200            [32, 145, 1024]       1,049,600\n",
      "         Dropout-201            [32, 145, 1024]               0\n",
      "       Attention-202            [32, 145, 1024]               0\n",
      "        Identity-203            [32, 145, 1024]               0\n",
      "       LayerNorm-204            [32, 145, 1024]           2,048\n",
      "          Linear-205            [32, 145, 4096]       4,198,400\n",
      "            GELU-206            [32, 145, 4096]               0\n",
      "         Dropout-207            [32, 145, 4096]               0\n",
      "          Linear-208            [32, 145, 1024]       4,195,328\n",
      "         Dropout-209            [32, 145, 1024]               0\n",
      "             Mlp-210            [32, 145, 1024]               0\n",
      "        Identity-211            [32, 145, 1024]               0\n",
      "           Block-212            [32, 145, 1024]               0\n",
      "       LayerNorm-213            [32, 145, 1024]           2,048\n",
      "          Linear-214            [32, 145, 3072]       3,148,800\n",
      "         Dropout-215         [32, 16, 145, 145]               0\n",
      "          Linear-216            [32, 145, 1024]       1,049,600\n",
      "         Dropout-217            [32, 145, 1024]               0\n",
      "       Attention-218            [32, 145, 1024]               0\n",
      "        Identity-219            [32, 145, 1024]               0\n",
      "       LayerNorm-220            [32, 145, 1024]           2,048\n",
      "          Linear-221            [32, 145, 4096]       4,198,400\n",
      "            GELU-222            [32, 145, 4096]               0\n",
      "         Dropout-223            [32, 145, 4096]               0\n",
      "          Linear-224            [32, 145, 1024]       4,195,328\n",
      "         Dropout-225            [32, 145, 1024]               0\n",
      "             Mlp-226            [32, 145, 1024]               0\n",
      "        Identity-227            [32, 145, 1024]               0\n",
      "           Block-228            [32, 145, 1024]               0\n",
      "       LayerNorm-229            [32, 145, 1024]           2,048\n",
      "          Linear-230            [32, 145, 3072]       3,148,800\n",
      "         Dropout-231         [32, 16, 145, 145]               0\n",
      "          Linear-232            [32, 145, 1024]       1,049,600\n",
      "         Dropout-233            [32, 145, 1024]               0\n",
      "       Attention-234            [32, 145, 1024]               0\n",
      "        Identity-235            [32, 145, 1024]               0\n",
      "       LayerNorm-236            [32, 145, 1024]           2,048\n",
      "          Linear-237            [32, 145, 4096]       4,198,400\n",
      "            GELU-238            [32, 145, 4096]               0\n",
      "         Dropout-239            [32, 145, 4096]               0\n",
      "          Linear-240            [32, 145, 1024]       4,195,328\n",
      "         Dropout-241            [32, 145, 1024]               0\n",
      "             Mlp-242            [32, 145, 1024]               0\n",
      "        Identity-243            [32, 145, 1024]               0\n",
      "           Block-244            [32, 145, 1024]               0\n",
      "       LayerNorm-245            [32, 145, 1024]           2,048\n",
      "          Linear-246            [32, 145, 3072]       3,148,800\n",
      "         Dropout-247         [32, 16, 145, 145]               0\n",
      "          Linear-248            [32, 145, 1024]       1,049,600\n",
      "         Dropout-249            [32, 145, 1024]               0\n",
      "       Attention-250            [32, 145, 1024]               0\n",
      "        Identity-251            [32, 145, 1024]               0\n",
      "       LayerNorm-252            [32, 145, 1024]           2,048\n",
      "          Linear-253            [32, 145, 4096]       4,198,400\n",
      "            GELU-254            [32, 145, 4096]               0\n",
      "         Dropout-255            [32, 145, 4096]               0\n",
      "          Linear-256            [32, 145, 1024]       4,195,328\n",
      "         Dropout-257            [32, 145, 1024]               0\n",
      "             Mlp-258            [32, 145, 1024]               0\n",
      "        Identity-259            [32, 145, 1024]               0\n",
      "           Block-260            [32, 145, 1024]               0\n",
      "       LayerNorm-261            [32, 145, 1024]           2,048\n",
      "          Linear-262            [32, 145, 3072]       3,148,800\n",
      "         Dropout-263         [32, 16, 145, 145]               0\n",
      "          Linear-264            [32, 145, 1024]       1,049,600\n",
      "         Dropout-265            [32, 145, 1024]               0\n",
      "       Attention-266            [32, 145, 1024]               0\n",
      "        Identity-267            [32, 145, 1024]               0\n",
      "       LayerNorm-268            [32, 145, 1024]           2,048\n",
      "          Linear-269            [32, 145, 4096]       4,198,400\n",
      "            GELU-270            [32, 145, 4096]               0\n",
      "         Dropout-271            [32, 145, 4096]               0\n",
      "          Linear-272            [32, 145, 1024]       4,195,328\n",
      "         Dropout-273            [32, 145, 1024]               0\n",
      "             Mlp-274            [32, 145, 1024]               0\n",
      "        Identity-275            [32, 145, 1024]               0\n",
      "           Block-276            [32, 145, 1024]               0\n",
      "       LayerNorm-277            [32, 145, 1024]           2,048\n",
      "          Linear-278            [32, 145, 3072]       3,148,800\n",
      "         Dropout-279         [32, 16, 145, 145]               0\n",
      "          Linear-280            [32, 145, 1024]       1,049,600\n",
      "         Dropout-281            [32, 145, 1024]               0\n",
      "       Attention-282            [32, 145, 1024]               0\n",
      "        Identity-283            [32, 145, 1024]               0\n",
      "       LayerNorm-284            [32, 145, 1024]           2,048\n",
      "          Linear-285            [32, 145, 4096]       4,198,400\n",
      "            GELU-286            [32, 145, 4096]               0\n",
      "         Dropout-287            [32, 145, 4096]               0\n",
      "          Linear-288            [32, 145, 1024]       4,195,328\n",
      "         Dropout-289            [32, 145, 1024]               0\n",
      "             Mlp-290            [32, 145, 1024]               0\n",
      "        Identity-291            [32, 145, 1024]               0\n",
      "           Block-292            [32, 145, 1024]               0\n",
      "       LayerNorm-293            [32, 145, 1024]           2,048\n",
      "          Linear-294            [32, 145, 3072]       3,148,800\n",
      "         Dropout-295         [32, 16, 145, 145]               0\n",
      "          Linear-296            [32, 145, 1024]       1,049,600\n",
      "         Dropout-297            [32, 145, 1024]               0\n",
      "       Attention-298            [32, 145, 1024]               0\n",
      "        Identity-299            [32, 145, 1024]               0\n",
      "       LayerNorm-300            [32, 145, 1024]           2,048\n",
      "          Linear-301            [32, 145, 4096]       4,198,400\n",
      "            GELU-302            [32, 145, 4096]               0\n",
      "         Dropout-303            [32, 145, 4096]               0\n",
      "          Linear-304            [32, 145, 1024]       4,195,328\n",
      "         Dropout-305            [32, 145, 1024]               0\n",
      "             Mlp-306            [32, 145, 1024]               0\n",
      "        Identity-307            [32, 145, 1024]               0\n",
      "           Block-308            [32, 145, 1024]               0\n",
      "       LayerNorm-309            [32, 145, 1024]           2,048\n",
      "          Linear-310            [32, 145, 3072]       3,148,800\n",
      "         Dropout-311         [32, 16, 145, 145]               0\n",
      "          Linear-312            [32, 145, 1024]       1,049,600\n",
      "         Dropout-313            [32, 145, 1024]               0\n",
      "       Attention-314            [32, 145, 1024]               0\n",
      "        Identity-315            [32, 145, 1024]               0\n",
      "       LayerNorm-316            [32, 145, 1024]           2,048\n",
      "          Linear-317            [32, 145, 4096]       4,198,400\n",
      "            GELU-318            [32, 145, 4096]               0\n",
      "         Dropout-319            [32, 145, 4096]               0\n",
      "          Linear-320            [32, 145, 1024]       4,195,328\n",
      "         Dropout-321            [32, 145, 1024]               0\n",
      "             Mlp-322            [32, 145, 1024]               0\n",
      "        Identity-323            [32, 145, 1024]               0\n",
      "           Block-324            [32, 145, 1024]               0\n",
      "       LayerNorm-325            [32, 145, 1024]           2,048\n",
      "          Linear-326            [32, 145, 3072]       3,148,800\n",
      "         Dropout-327         [32, 16, 145, 145]               0\n",
      "          Linear-328            [32, 145, 1024]       1,049,600\n",
      "         Dropout-329            [32, 145, 1024]               0\n",
      "       Attention-330            [32, 145, 1024]               0\n",
      "        Identity-331            [32, 145, 1024]               0\n",
      "       LayerNorm-332            [32, 145, 1024]           2,048\n",
      "          Linear-333            [32, 145, 4096]       4,198,400\n",
      "            GELU-334            [32, 145, 4096]               0\n",
      "         Dropout-335            [32, 145, 4096]               0\n",
      "          Linear-336            [32, 145, 1024]       4,195,328\n",
      "         Dropout-337            [32, 145, 1024]               0\n",
      "             Mlp-338            [32, 145, 1024]               0\n",
      "        Identity-339            [32, 145, 1024]               0\n",
      "           Block-340            [32, 145, 1024]               0\n",
      "       LayerNorm-341            [32, 145, 1024]           2,048\n",
      "          Linear-342            [32, 145, 3072]       3,148,800\n",
      "         Dropout-343         [32, 16, 145, 145]               0\n",
      "          Linear-344            [32, 145, 1024]       1,049,600\n",
      "         Dropout-345            [32, 145, 1024]               0\n",
      "       Attention-346            [32, 145, 1024]               0\n",
      "        Identity-347            [32, 145, 1024]               0\n",
      "       LayerNorm-348            [32, 145, 1024]           2,048\n",
      "          Linear-349            [32, 145, 4096]       4,198,400\n",
      "            GELU-350            [32, 145, 4096]               0\n",
      "         Dropout-351            [32, 145, 4096]               0\n",
      "          Linear-352            [32, 145, 1024]       4,195,328\n",
      "         Dropout-353            [32, 145, 1024]               0\n",
      "             Mlp-354            [32, 145, 1024]               0\n",
      "        Identity-355            [32, 145, 1024]               0\n",
      "           Block-356            [32, 145, 1024]               0\n",
      "       LayerNorm-357            [32, 145, 1024]           2,048\n",
      "          Linear-358            [32, 145, 3072]       3,148,800\n",
      "         Dropout-359         [32, 16, 145, 145]               0\n",
      "          Linear-360            [32, 145, 1024]       1,049,600\n",
      "         Dropout-361            [32, 145, 1024]               0\n",
      "       Attention-362            [32, 145, 1024]               0\n",
      "        Identity-363            [32, 145, 1024]               0\n",
      "       LayerNorm-364            [32, 145, 1024]           2,048\n",
      "          Linear-365            [32, 145, 4096]       4,198,400\n",
      "            GELU-366            [32, 145, 4096]               0\n",
      "         Dropout-367            [32, 145, 4096]               0\n",
      "          Linear-368            [32, 145, 1024]       4,195,328\n",
      "         Dropout-369            [32, 145, 1024]               0\n",
      "             Mlp-370            [32, 145, 1024]               0\n",
      "        Identity-371            [32, 145, 1024]               0\n",
      "           Block-372            [32, 145, 1024]               0\n",
      "       LayerNorm-373            [32, 145, 1024]           2,048\n",
      "          Linear-374            [32, 145, 3072]       3,148,800\n",
      "         Dropout-375         [32, 16, 145, 145]               0\n",
      "          Linear-376            [32, 145, 1024]       1,049,600\n",
      "         Dropout-377            [32, 145, 1024]               0\n",
      "       Attention-378            [32, 145, 1024]               0\n",
      "        Identity-379            [32, 145, 1024]               0\n",
      "       LayerNorm-380            [32, 145, 1024]           2,048\n",
      "          Linear-381            [32, 145, 4096]       4,198,400\n",
      "            GELU-382            [32, 145, 4096]               0\n",
      "         Dropout-383            [32, 145, 4096]               0\n",
      "          Linear-384            [32, 145, 1024]       4,195,328\n",
      "         Dropout-385            [32, 145, 1024]               0\n",
      "             Mlp-386            [32, 145, 1024]               0\n",
      "        Identity-387            [32, 145, 1024]               0\n",
      "           Block-388            [32, 145, 1024]               0\n",
      "       LayerNorm-389            [32, 145, 1024]           2,048\n",
      "        Identity-390                 [32, 1024]               0\n",
      "          Linear-391                   [32, 18]          18,450\n",
      "VisionTransformer-392                   [32, 18]               0\n",
      "================================================================\n",
      "Total params: 305,476,626\n",
      "Trainable params: 305,476,626\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 54.00\n",
      "Forward/backward pass size (MB): 24771.85\n",
      "Params size (MB): 1165.30\n",
      "Estimated Total Size (MB): 25991.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary_\n",
    "\n",
    "summary_(model,(3,384,384),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e425094-b760-46a8-9e7a-b406a452edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training..\n",
      "Epoch start..\n",
      "Epoch [1/200], Step [3/202], Loss: 2.4173, Accuracy: 25.00%, F1_Score: 0.17\n",
      "Epoch [1/200], Step [6/202], Loss: 1.9188, Accuracy: 40.62%, F1_Score: 0.28\n",
      "Epoch [1/200], Step [9/202], Loss: 1.3564, Accuracy: 71.88%, F1_Score: 0.46\n",
      "Epoch [1/200], Step [12/202], Loss: 1.2639, Accuracy: 59.38%, F1_Score: 0.39\n",
      "Epoch [1/200], Step [15/202], Loss: 1.0777, Accuracy: 62.50%, F1_Score: 0.48\n",
      "Epoch [1/200], Step [18/202], Loss: 0.6968, Accuracy: 87.50%, F1_Score: 0.72\n",
      "Epoch [1/200], Step [21/202], Loss: 0.8380, Accuracy: 81.25%, F1_Score: 0.62\n",
      "Epoch [1/200], Step [24/202], Loss: 0.9561, Accuracy: 68.75%, F1_Score: 0.55\n",
      "Epoch [1/200], Step [27/202], Loss: 0.7445, Accuracy: 75.00%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [30/202], Loss: 1.0206, Accuracy: 68.75%, F1_Score: 0.55\n",
      "Epoch [1/200], Step [33/202], Loss: 0.7152, Accuracy: 65.62%, F1_Score: 0.59\n",
      "Epoch [1/200], Step [36/202], Loss: 0.4608, Accuracy: 84.38%, F1_Score: 0.68\n",
      "Epoch [1/200], Step [39/202], Loss: 0.5364, Accuracy: 78.12%, F1_Score: 0.66\n",
      "Epoch [1/200], Step [42/202], Loss: 0.2839, Accuracy: 90.62%, F1_Score: 0.80\n",
      "Epoch [1/200], Step [45/202], Loss: 0.2837, Accuracy: 96.88%, F1_Score: 0.82\n",
      "Epoch [1/200], Step [48/202], Loss: 0.3930, Accuracy: 84.38%, F1_Score: 0.74\n",
      "Epoch [1/200], Step [51/202], Loss: 0.4431, Accuracy: 84.38%, F1_Score: 0.76\n",
      "Epoch [1/200], Step [54/202], Loss: 0.4729, Accuracy: 87.50%, F1_Score: 0.76\n",
      "Epoch [1/200], Step [57/202], Loss: 0.7176, Accuracy: 81.25%, F1_Score: 0.75\n",
      "Epoch [1/200], Step [60/202], Loss: 0.2465, Accuracy: 90.62%, F1_Score: 0.92\n",
      "Epoch [1/200], Step [63/202], Loss: 1.1314, Accuracy: 62.50%, F1_Score: 0.57\n",
      "Epoch [1/200], Step [66/202], Loss: 0.4833, Accuracy: 90.62%, F1_Score: 0.79\n",
      "Epoch [1/200], Step [69/202], Loss: 0.4454, Accuracy: 87.50%, F1_Score: 0.75\n",
      "Epoch [1/200], Step [72/202], Loss: 0.4346, Accuracy: 84.38%, F1_Score: 0.64\n",
      "Epoch [1/200], Step [75/202], Loss: 0.2316, Accuracy: 90.62%, F1_Score: 0.85\n",
      "Epoch [1/200], Step [78/202], Loss: 0.2490, Accuracy: 90.62%, F1_Score: 0.86\n",
      "Epoch [1/200], Step [81/202], Loss: 0.2981, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [1/200], Step [84/202], Loss: 0.5700, Accuracy: 84.38%, F1_Score: 0.69\n",
      "Epoch [1/200], Step [87/202], Loss: 0.5665, Accuracy: 71.88%, F1_Score: 0.55\n",
      "Epoch [1/200], Step [90/202], Loss: 0.3435, Accuracy: 81.25%, F1_Score: 0.60\n",
      "Epoch [1/200], Step [93/202], Loss: 0.4197, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [1/200], Step [96/202], Loss: 0.3831, Accuracy: 87.50%, F1_Score: 0.82\n",
      "Epoch [1/200], Step [99/202], Loss: 0.1688, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [1/200], Step [102/202], Loss: 0.5586, Accuracy: 75.00%, F1_Score: 0.67\n",
      "Epoch [1/200], Step [105/202], Loss: 0.1798, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [1/200], Step [108/202], Loss: 0.5170, Accuracy: 87.50%, F1_Score: 0.72\n",
      "Epoch [1/200], Step [111/202], Loss: 0.4784, Accuracy: 81.25%, F1_Score: 0.73\n",
      "Epoch [1/200], Step [114/202], Loss: 0.4015, Accuracy: 87.50%, F1_Score: 0.70\n",
      "Epoch [1/200], Step [117/202], Loss: 0.3898, Accuracy: 87.50%, F1_Score: 0.67\n",
      "Epoch [1/200], Step [120/202], Loss: 0.2207, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [1/200], Step [123/202], Loss: 0.1330, Accuracy: 93.75%, F1_Score: 0.91\n",
      "Epoch [1/200], Step [126/202], Loss: 0.4302, Accuracy: 81.25%, F1_Score: 0.72\n",
      "Epoch [1/200], Step [129/202], Loss: 0.4930, Accuracy: 81.25%, F1_Score: 0.74\n",
      "Epoch [1/200], Step [132/202], Loss: 0.3140, Accuracy: 87.50%, F1_Score: 0.83\n",
      "Epoch [1/200], Step [135/202], Loss: 0.3731, Accuracy: 81.25%, F1_Score: 0.73\n",
      "Epoch [1/200], Step [138/202], Loss: 0.5218, Accuracy: 87.50%, F1_Score: 0.75\n",
      "Epoch [1/200], Step [141/202], Loss: 0.2944, Accuracy: 87.50%, F1_Score: 0.76\n",
      "Epoch [1/200], Step [144/202], Loss: 0.2812, Accuracy: 90.62%, F1_Score: 0.86\n",
      "Epoch [1/200], Step [147/202], Loss: 0.1831, Accuracy: 90.62%, F1_Score: 0.87\n",
      "Epoch [1/200], Step [150/202], Loss: 0.2813, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [1/200], Step [153/202], Loss: 0.6415, Accuracy: 78.12%, F1_Score: 0.51\n",
      "Epoch [1/200], Step [156/202], Loss: 0.3993, Accuracy: 90.62%, F1_Score: 0.72\n",
      "Epoch [1/200], Step [159/202], Loss: 0.0899, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [1/200], Step [162/202], Loss: 0.3504, Accuracy: 84.38%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [165/202], Loss: 0.1430, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [1/200], Step [168/202], Loss: 0.2807, Accuracy: 87.50%, F1_Score: 0.78\n",
      "Epoch [1/200], Step [171/202], Loss: 0.3073, Accuracy: 87.50%, F1_Score: 0.77\n",
      "Epoch [1/200], Step [174/202], Loss: 0.3124, Accuracy: 90.62%, F1_Score: 0.91\n",
      "Epoch [1/200], Step [177/202], Loss: 0.6212, Accuracy: 84.38%, F1_Score: 0.74\n",
      "Epoch [1/200], Step [180/202], Loss: 0.3433, Accuracy: 87.50%, F1_Score: 0.73\n",
      "Epoch [1/200], Step [183/202], Loss: 0.3090, Accuracy: 90.62%, F1_Score: 0.80\n",
      "Epoch [1/200], Step [186/202], Loss: 0.2291, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [1/200], Step [189/202], Loss: 0.2746, Accuracy: 87.50%, F1_Score: 0.65\n",
      "Epoch [1/200], Step [192/202], Loss: 0.3539, Accuracy: 90.62%, F1_Score: 0.86\n",
      "Epoch [1/200], Step [195/202], Loss: 0.2334, Accuracy: 90.62%, F1_Score: 0.79\n",
      "Epoch [1/200], Step [198/202], Loss: 0.5019, Accuracy: 87.50%, F1_Score: 0.76\n",
      "Epoch [1/200], Step [201/202], Loss: 0.4111, Accuracy: 84.38%, F1_Score: 0.61\n",
      "------------Epoch Finish------------\n",
      "Epoch [1/200], Accuracy: 82.52%, F1_Score: 0.72\n",
      "Start validation #1\n",
      "Validation #1  Accuracy: 86.88% F1_Score: 0.77 Average Loss: 0.3849\n",
      "Best performance at epoch: 1\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 258.4512922629947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [04:27<14:47:12, 267.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [2/200], Step [3/202], Loss: 0.1848, Accuracy: 87.50%, F1_Score: 0.76\n",
      "Epoch [2/200], Step [6/202], Loss: 0.0673, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [9/202], Loss: 0.0973, Accuracy: 96.88%, F1_Score: 0.93\n",
      "Epoch [2/200], Step [12/202], Loss: 0.2041, Accuracy: 90.62%, F1_Score: 0.76\n",
      "Epoch [2/200], Step [15/202], Loss: 0.0489, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [18/202], Loss: 0.1880, Accuracy: 87.50%, F1_Score: 0.80\n",
      "Epoch [2/200], Step [21/202], Loss: 0.1246, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [2/200], Step [24/202], Loss: 0.1811, Accuracy: 93.75%, F1_Score: 0.91\n",
      "Epoch [2/200], Step [27/202], Loss: 0.5444, Accuracy: 84.38%, F1_Score: 0.74\n",
      "Epoch [2/200], Step [30/202], Loss: 0.4528, Accuracy: 84.38%, F1_Score: 0.71\n",
      "Epoch [2/200], Step [33/202], Loss: 0.1929, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [2/200], Step [36/202], Loss: 0.1608, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [2/200], Step [39/202], Loss: 0.2153, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [2/200], Step [42/202], Loss: 0.0760, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [2/200], Step [45/202], Loss: 0.0534, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [48/202], Loss: 0.4247, Accuracy: 84.38%, F1_Score: 0.66\n",
      "Epoch [2/200], Step [51/202], Loss: 0.2372, Accuracy: 90.62%, F1_Score: 0.81\n",
      "Epoch [2/200], Step [54/202], Loss: 0.5322, Accuracy: 81.25%, F1_Score: 0.76\n",
      "Epoch [2/200], Step [57/202], Loss: 0.4644, Accuracy: 84.38%, F1_Score: 0.84\n",
      "Epoch [2/200], Step [60/202], Loss: 0.4538, Accuracy: 87.50%, F1_Score: 0.82\n",
      "Epoch [2/200], Step [63/202], Loss: 0.1889, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [2/200], Step [66/202], Loss: 0.4645, Accuracy: 90.62%, F1_Score: 0.78\n",
      "Epoch [2/200], Step [69/202], Loss: 0.2780, Accuracy: 90.62%, F1_Score: 0.79\n",
      "Epoch [2/200], Step [72/202], Loss: 0.4688, Accuracy: 87.50%, F1_Score: 0.79\n",
      "Epoch [2/200], Step [75/202], Loss: 0.2681, Accuracy: 90.62%, F1_Score: 0.85\n",
      "Epoch [2/200], Step [78/202], Loss: 0.3309, Accuracy: 90.62%, F1_Score: 0.83\n",
      "Epoch [2/200], Step [81/202], Loss: 0.4394, Accuracy: 87.50%, F1_Score: 0.78\n",
      "Epoch [2/200], Step [84/202], Loss: 0.1474, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [2/200], Step [87/202], Loss: 0.3150, Accuracy: 90.62%, F1_Score: 0.61\n",
      "Epoch [2/200], Step [90/202], Loss: 0.0790, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [93/202], Loss: 0.3705, Accuracy: 84.38%, F1_Score: 0.65\n",
      "Epoch [2/200], Step [96/202], Loss: 0.3890, Accuracy: 84.38%, F1_Score: 0.77\n",
      "Epoch [2/200], Step [99/202], Loss: 0.1406, Accuracy: 93.75%, F1_Score: 0.84\n",
      "Epoch [2/200], Step [102/202], Loss: 0.3769, Accuracy: 78.12%, F1_Score: 0.70\n",
      "Epoch [2/200], Step [105/202], Loss: 0.2371, Accuracy: 90.62%, F1_Score: 0.79\n",
      "Epoch [2/200], Step [108/202], Loss: 0.1105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [111/202], Loss: 0.3037, Accuracy: 90.62%, F1_Score: 0.87\n",
      "Epoch [2/200], Step [114/202], Loss: 0.1801, Accuracy: 90.62%, F1_Score: 0.82\n",
      "Epoch [2/200], Step [117/202], Loss: 0.1883, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [2/200], Step [120/202], Loss: 0.2303, Accuracy: 90.62%, F1_Score: 0.84\n",
      "Epoch [2/200], Step [123/202], Loss: 0.0699, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [126/202], Loss: 0.1201, Accuracy: 96.88%, F1_Score: 0.94\n",
      "Epoch [2/200], Step [129/202], Loss: 0.0578, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [132/202], Loss: 0.2025, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [2/200], Step [135/202], Loss: 0.1042, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [2/200], Step [138/202], Loss: 0.2775, Accuracy: 90.62%, F1_Score: 0.73\n",
      "Epoch [2/200], Step [141/202], Loss: 0.4274, Accuracy: 84.38%, F1_Score: 0.73\n",
      "Epoch [2/200], Step [144/202], Loss: 0.1447, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [2/200], Step [147/202], Loss: 0.1193, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [2/200], Step [150/202], Loss: 0.0725, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [2/200], Step [153/202], Loss: 0.4143, Accuracy: 87.50%, F1_Score: 0.75\n",
      "Epoch [2/200], Step [156/202], Loss: 0.3408, Accuracy: 87.50%, F1_Score: 0.84\n",
      "Epoch [2/200], Step [159/202], Loss: 0.1299, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [2/200], Step [162/202], Loss: 0.0502, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [165/202], Loss: 0.1897, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [2/200], Step [168/202], Loss: 0.1680, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [2/200], Step [171/202], Loss: 0.3447, Accuracy: 87.50%, F1_Score: 0.81\n",
      "Epoch [2/200], Step [174/202], Loss: 0.1508, Accuracy: 90.62%, F1_Score: 0.75\n",
      "Epoch [2/200], Step [177/202], Loss: 0.1924, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [2/200], Step [180/202], Loss: 0.4351, Accuracy: 84.38%, F1_Score: 0.71\n",
      "Epoch [2/200], Step [183/202], Loss: 0.0745, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [186/202], Loss: 0.0486, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [2/200], Step [189/202], Loss: 0.1340, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [2/200], Step [192/202], Loss: 0.1466, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [2/200], Step [195/202], Loss: 0.4105, Accuracy: 81.25%, F1_Score: 0.71\n",
      "Epoch [2/200], Step [198/202], Loss: 0.2798, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [2/200], Step [201/202], Loss: 0.1864, Accuracy: 90.62%, F1_Score: 0.73\n",
      "------------Epoch Finish------------\n",
      "Epoch [2/200], Accuracy: 92.26%, F1_Score: 0.86\n",
      "Start validation #2\n",
      "Validation #2  Accuracy: 90.44% F1_Score: 0.83 Average Loss: 0.3021\n",
      "Best performance at epoch: 2\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 265.08044739998877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [09:01<14:49:23, 269.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [3/200], Step [3/202], Loss: 0.0485, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [6/202], Loss: 0.0733, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [9/202], Loss: 0.3180, Accuracy: 87.50%, F1_Score: 0.79\n",
      "Epoch [3/200], Step [12/202], Loss: 0.1301, Accuracy: 96.88%, F1_Score: 0.93\n",
      "Epoch [3/200], Step [15/202], Loss: 0.1007, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [3/200], Step [18/202], Loss: 0.0460, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [21/202], Loss: 0.1117, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [3/200], Step [24/202], Loss: 0.1023, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [3/200], Step [27/202], Loss: 0.0381, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [30/202], Loss: 0.1290, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [33/202], Loss: 0.0866, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [36/202], Loss: 0.1157, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [39/202], Loss: 0.1809, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [3/200], Step [42/202], Loss: 0.1549, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [45/202], Loss: 0.3214, Accuracy: 90.62%, F1_Score: 0.84\n",
      "Epoch [3/200], Step [48/202], Loss: 0.0769, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [3/200], Step [51/202], Loss: 0.1313, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [3/200], Step [54/202], Loss: 0.2447, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [3/200], Step [57/202], Loss: 0.3242, Accuracy: 90.62%, F1_Score: 0.75\n",
      "Epoch [3/200], Step [60/202], Loss: 0.1517, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [3/200], Step [63/202], Loss: 0.0861, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [66/202], Loss: 0.0812, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [3/200], Step [69/202], Loss: 0.1237, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [3/200], Step [72/202], Loss: 0.0722, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [75/202], Loss: 0.1362, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [3/200], Step [78/202], Loss: 0.1557, Accuracy: 90.62%, F1_Score: 0.86\n",
      "Epoch [3/200], Step [81/202], Loss: 0.0703, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [84/202], Loss: 0.1902, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [3/200], Step [87/202], Loss: 0.0881, Accuracy: 93.75%, F1_Score: 0.84\n",
      "Epoch [3/200], Step [90/202], Loss: 0.1086, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [93/202], Loss: 0.0992, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [3/200], Step [96/202], Loss: 0.3489, Accuracy: 87.50%, F1_Score: 0.80\n",
      "Epoch [3/200], Step [99/202], Loss: 0.1033, Accuracy: 90.62%, F1_Score: 0.80\n",
      "Epoch [3/200], Step [102/202], Loss: 0.2699, Accuracy: 90.62%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [105/202], Loss: 0.1087, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [108/202], Loss: 0.0369, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [111/202], Loss: 0.1412, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [3/200], Step [114/202], Loss: 0.0300, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [117/202], Loss: 0.0406, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [120/202], Loss: 0.0291, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [123/202], Loss: 0.0654, Accuracy: 96.88%, F1_Score: 0.95\n",
      "Epoch [3/200], Step [126/202], Loss: 0.0892, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [129/202], Loss: 0.0695, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [132/202], Loss: 0.0216, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [135/202], Loss: 0.0178, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [138/202], Loss: 0.0273, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [141/202], Loss: 0.1076, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [3/200], Step [144/202], Loss: 0.0144, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [147/202], Loss: 0.0562, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [3/200], Step [150/202], Loss: 0.1517, Accuracy: 90.62%, F1_Score: 0.94\n",
      "Epoch [3/200], Step [153/202], Loss: 0.0657, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [3/200], Step [156/202], Loss: 0.1021, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [3/200], Step [159/202], Loss: 0.0436, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [162/202], Loss: 0.0719, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [3/200], Step [165/202], Loss: 0.1214, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [3/200], Step [168/202], Loss: 0.0394, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [171/202], Loss: 0.1280, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [3/200], Step [174/202], Loss: 0.0921, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [3/200], Step [177/202], Loss: 0.2081, Accuracy: 90.62%, F1_Score: 0.79\n",
      "Epoch [3/200], Step [180/202], Loss: 0.1878, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [3/200], Step [183/202], Loss: 0.0572, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [186/202], Loss: 0.1136, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [3/200], Step [189/202], Loss: 0.2140, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [3/200], Step [192/202], Loss: 0.1890, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [3/200], Step [195/202], Loss: 0.0173, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [198/202], Loss: 0.0306, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [3/200], Step [201/202], Loss: 0.0404, Accuracy: 96.88%, F1_Score: 0.96\n",
      "------------Epoch Finish------------\n",
      "Epoch [3/200], Accuracy: 96.38%, F1_Score: 0.93\n",
      "Start validation #3\n",
      "Validation #3  Accuracy: 91.62% F1_Score: 0.85 Average Loss: 0.2646\n",
      "Best performance at epoch: 3\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 265.70094579894794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [13:36<14:50:01, 271.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [4/200], Step [3/202], Loss: 0.0505, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [6/202], Loss: 0.1706, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [4/200], Step [9/202], Loss: 0.0504, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [12/202], Loss: 0.0606, Accuracy: 96.88%, F1_Score: 0.95\n",
      "Epoch [4/200], Step [15/202], Loss: 0.0410, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [18/202], Loss: 0.0692, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [4/200], Step [21/202], Loss: 0.1183, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [4/200], Step [24/202], Loss: 0.0920, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [4/200], Step [27/202], Loss: 0.0221, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [30/202], Loss: 0.0605, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [4/200], Step [33/202], Loss: 0.0506, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [36/202], Loss: 0.0415, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [39/202], Loss: 0.1016, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [42/202], Loss: 0.0296, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [45/202], Loss: 0.0158, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [48/202], Loss: 0.0187, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [51/202], Loss: 0.0219, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [54/202], Loss: 0.1060, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [4/200], Step [57/202], Loss: 0.0631, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [60/202], Loss: 0.0524, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [63/202], Loss: 0.0106, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [66/202], Loss: 0.0893, Accuracy: 93.75%, F1_Score: 0.79\n",
      "Epoch [4/200], Step [69/202], Loss: 0.3652, Accuracy: 90.62%, F1_Score: 0.80\n",
      "Epoch [4/200], Step [72/202], Loss: 0.0220, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [75/202], Loss: 0.0091, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [78/202], Loss: 0.1251, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [4/200], Step [81/202], Loss: 0.0135, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [84/202], Loss: 0.1968, Accuracy: 90.62%, F1_Score: 0.81\n",
      "Epoch [4/200], Step [87/202], Loss: 0.0148, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [90/202], Loss: 0.1287, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [4/200], Step [93/202], Loss: 0.0275, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [96/202], Loss: 0.0311, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [99/202], Loss: 0.0565, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [102/202], Loss: 0.0406, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [105/202], Loss: 0.0383, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [108/202], Loss: 0.0318, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [111/202], Loss: 0.1657, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [4/200], Step [114/202], Loss: 0.0635, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [4/200], Step [117/202], Loss: 0.1380, Accuracy: 93.75%, F1_Score: 0.79\n",
      "Epoch [4/200], Step [120/202], Loss: 0.0104, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [123/202], Loss: 0.0179, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [126/202], Loss: 0.0252, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [129/202], Loss: 0.0201, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [132/202], Loss: 0.0078, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [135/202], Loss: 0.0342, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [138/202], Loss: 0.0116, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [141/202], Loss: 0.1689, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [4/200], Step [144/202], Loss: 0.0324, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [147/202], Loss: 0.0693, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [150/202], Loss: 0.1260, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [4/200], Step [153/202], Loss: 0.0060, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [156/202], Loss: 0.0423, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [159/202], Loss: 0.0951, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [4/200], Step [162/202], Loss: 0.1781, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [4/200], Step [165/202], Loss: 0.0246, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [168/202], Loss: 0.0281, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [171/202], Loss: 0.0189, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [174/202], Loss: 0.1322, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [4/200], Step [177/202], Loss: 0.0341, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [180/202], Loss: 0.0062, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [183/202], Loss: 0.1097, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [4/200], Step [186/202], Loss: 0.1425, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [4/200], Step [189/202], Loss: 0.0190, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [4/200], Step [192/202], Loss: 0.2218, Accuracy: 90.62%, F1_Score: 0.88\n",
      "Epoch [4/200], Step [195/202], Loss: 0.2193, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [4/200], Step [198/202], Loss: 0.1438, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [4/200], Step [201/202], Loss: 0.2699, Accuracy: 90.62%, F1_Score: 0.81\n",
      "------------Epoch Finish------------\n",
      "Epoch [4/200], Accuracy: 97.63%, F1_Score: 0.95\n",
      "Start validation #4\n",
      "Validation #4  Accuracy: 92.75% F1_Score: 0.87 Average Loss: 0.2412\n",
      "Best performance at epoch: 4\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 265.2267226180411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [18:10<14:48:36, 272.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [5/200], Step [3/202], Loss: 0.0080, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [6/202], Loss: 0.1038, Accuracy: 96.88%, F1_Score: 0.94\n",
      "Epoch [5/200], Step [9/202], Loss: 0.0158, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [12/202], Loss: 0.1343, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [5/200], Step [15/202], Loss: 0.0969, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [5/200], Step [18/202], Loss: 0.0091, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [21/202], Loss: 0.1423, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [5/200], Step [24/202], Loss: 0.0857, Accuracy: 93.75%, F1_Score: 0.71\n",
      "Epoch [5/200], Step [27/202], Loss: 0.1591, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [5/200], Step [30/202], Loss: 0.1039, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [5/200], Step [33/202], Loss: 0.0268, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [36/202], Loss: 0.0732, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [5/200], Step [39/202], Loss: 0.1239, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [5/200], Step [42/202], Loss: 0.0941, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [5/200], Step [45/202], Loss: 0.1029, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [5/200], Step [48/202], Loss: 0.0295, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [51/202], Loss: 0.0429, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [5/200], Step [54/202], Loss: 0.0283, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [57/202], Loss: 0.1506, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [5/200], Step [60/202], Loss: 0.0359, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [63/202], Loss: 0.0198, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [66/202], Loss: 0.0139, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [69/202], Loss: 0.1224, Accuracy: 93.75%, F1_Score: 0.78\n",
      "Epoch [5/200], Step [72/202], Loss: 0.0654, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [5/200], Step [75/202], Loss: 0.0108, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [78/202], Loss: 0.0902, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [5/200], Step [81/202], Loss: 0.0147, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [84/202], Loss: 0.0341, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [87/202], Loss: 0.0170, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [90/202], Loss: 0.0061, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [93/202], Loss: 0.0514, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [5/200], Step [96/202], Loss: 0.0582, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [5/200], Step [99/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [102/202], Loss: 0.0836, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [5/200], Step [105/202], Loss: 0.2162, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [5/200], Step [108/202], Loss: 0.0158, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [111/202], Loss: 0.0631, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [5/200], Step [114/202], Loss: 0.0199, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [117/202], Loss: 0.0512, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [5/200], Step [120/202], Loss: 0.0331, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [123/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [126/202], Loss: 0.0253, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [129/202], Loss: 0.0263, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [132/202], Loss: 0.0071, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [135/202], Loss: 0.0488, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [5/200], Step [138/202], Loss: 0.0220, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [141/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [144/202], Loss: 0.0301, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [5/200], Step [147/202], Loss: 0.0141, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [150/202], Loss: 0.0107, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [153/202], Loss: 0.0091, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [156/202], Loss: 0.0299, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [159/202], Loss: 0.0132, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [162/202], Loss: 0.2363, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [5/200], Step [165/202], Loss: 0.1928, Accuracy: 87.50%, F1_Score: 0.84\n",
      "Epoch [5/200], Step [168/202], Loss: 0.0082, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [171/202], Loss: 0.0301, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [174/202], Loss: 0.0725, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [5/200], Step [177/202], Loss: 0.1572, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [5/200], Step [180/202], Loss: 0.1287, Accuracy: 90.62%, F1_Score: 0.89\n",
      "Epoch [5/200], Step [183/202], Loss: 0.0255, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [186/202], Loss: 0.1538, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [5/200], Step [189/202], Loss: 0.0736, Accuracy: 96.88%, F1_Score: 0.88\n",
      "Epoch [5/200], Step [192/202], Loss: 0.0865, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [5/200], Step [195/202], Loss: 0.0712, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [5/200], Step [198/202], Loss: 0.0249, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [5/200], Step [201/202], Loss: 0.0139, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [5/200], Accuracy: 98.02%, F1_Score: 0.96\n",
      "Start validation #5\n",
      "Validation #5  Accuracy: 90.69% F1_Score: 0.85 Average Loss: 0.3331\n",
      "Epoch end..\n",
      "epoch time : 257.36738838703604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [22:37<14:38:34, 270.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [6/200], Step [3/202], Loss: 0.0659, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [6/200], Step [6/202], Loss: 0.0314, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [9/202], Loss: 0.0088, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [12/202], Loss: 0.0593, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [15/202], Loss: 0.0593, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [6/200], Step [18/202], Loss: 0.1131, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [6/200], Step [21/202], Loss: 0.0095, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [24/202], Loss: 0.1335, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [6/200], Step [27/202], Loss: 0.0062, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [30/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [33/202], Loss: 0.0501, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [36/202], Loss: 0.0086, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [39/202], Loss: 0.0402, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [42/202], Loss: 0.0111, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [45/202], Loss: 0.0077, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [48/202], Loss: 0.0167, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [51/202], Loss: 0.0592, Accuracy: 96.88%, F1_Score: 0.86\n",
      "Epoch [6/200], Step [54/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [57/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [60/202], Loss: 0.0158, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [63/202], Loss: 0.0125, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [66/202], Loss: 0.0230, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [69/202], Loss: 0.0390, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [6/200], Step [72/202], Loss: 0.0356, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [75/202], Loss: 0.0653, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [6/200], Step [78/202], Loss: 0.0107, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [81/202], Loss: 0.0091, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [84/202], Loss: 0.0100, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [87/202], Loss: 0.0214, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [90/202], Loss: 0.0153, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [93/202], Loss: 0.0057, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [96/202], Loss: 0.0158, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [99/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [102/202], Loss: 0.0524, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [6/200], Step [105/202], Loss: 0.0043, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [108/202], Loss: 0.0290, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [6/200], Step [111/202], Loss: 0.0335, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [6/200], Step [114/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [117/202], Loss: 0.0207, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [120/202], Loss: 0.0124, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [123/202], Loss: 0.0166, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [126/202], Loss: 0.1152, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [6/200], Step [129/202], Loss: 0.0944, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [6/200], Step [132/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [135/202], Loss: 0.0429, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [6/200], Step [138/202], Loss: 0.1723, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [6/200], Step [141/202], Loss: 0.0609, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [6/200], Step [144/202], Loss: 0.0178, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [147/202], Loss: 0.0083, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [150/202], Loss: 0.1689, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [6/200], Step [153/202], Loss: 0.0236, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [156/202], Loss: 0.3709, Accuracy: 93.75%, F1_Score: 0.85\n",
      "Epoch [6/200], Step [159/202], Loss: 0.0160, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [162/202], Loss: 0.0186, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [165/202], Loss: 0.0127, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [168/202], Loss: 0.0094, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [171/202], Loss: 0.0089, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [174/202], Loss: 0.2311, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [6/200], Step [177/202], Loss: 0.0443, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [6/200], Step [180/202], Loss: 0.0129, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [183/202], Loss: 0.0312, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [186/202], Loss: 0.0814, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [6/200], Step [189/202], Loss: 0.0634, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [6/200], Step [192/202], Loss: 0.0687, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [6/200], Step [195/202], Loss: 0.1836, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [6/200], Step [198/202], Loss: 0.0278, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [6/200], Step [201/202], Loss: 0.0056, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [6/200], Accuracy: 98.48%, F1_Score: 0.97\n",
      "Start validation #6\n",
      "Validation #6  Accuracy: 90.81% F1_Score: 0.85 Average Loss: 0.3325\n",
      "Epoch end..\n",
      "epoch time : 255.6812806900125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [27:01<14:28:34, 268.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [7/200], Step [3/202], Loss: 0.0257, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [6/202], Loss: 0.0074, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [9/202], Loss: 0.0096, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [12/202], Loss: 0.0138, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [15/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [18/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [21/202], Loss: 0.0306, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [24/202], Loss: 0.0088, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [27/202], Loss: 0.0107, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [30/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [33/202], Loss: 0.1504, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [7/200], Step [36/202], Loss: 0.0085, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [39/202], Loss: 0.0195, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [42/202], Loss: 0.0155, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [45/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [48/202], Loss: 0.0336, Accuracy: 96.88%, F1_Score: 0.94\n",
      "Epoch [7/200], Step [51/202], Loss: 0.0858, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [7/200], Step [54/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [57/202], Loss: 0.0070, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [60/202], Loss: 0.0089, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [63/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [66/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [69/202], Loss: 0.0116, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [72/202], Loss: 0.0084, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [75/202], Loss: 0.1930, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [78/202], Loss: 0.0054, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [81/202], Loss: 0.0100, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [84/202], Loss: 0.0035, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [87/202], Loss: 0.0390, Accuracy: 96.88%, F1_Score: 0.89\n",
      "Epoch [7/200], Step [90/202], Loss: 0.0356, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [7/200], Step [93/202], Loss: 0.0333, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [96/202], Loss: 0.0845, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [7/200], Step [99/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [102/202], Loss: 0.0297, Accuracy: 96.88%, F1_Score: 0.85\n",
      "Epoch [7/200], Step [105/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [108/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [111/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [114/202], Loss: 0.0908, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [7/200], Step [117/202], Loss: 0.0194, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [120/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [123/202], Loss: 0.0156, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [126/202], Loss: 0.0103, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [129/202], Loss: 0.0042, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [132/202], Loss: 0.0132, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [135/202], Loss: 0.0606, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [138/202], Loss: 0.0378, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [141/202], Loss: 0.0051, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [144/202], Loss: 0.0816, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [147/202], Loss: 0.1683, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [150/202], Loss: 0.0923, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [7/200], Step [153/202], Loss: 0.0037, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [156/202], Loss: 0.0152, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [159/202], Loss: 0.0891, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [7/200], Step [162/202], Loss: 0.0307, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [165/202], Loss: 0.0190, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [168/202], Loss: 0.1163, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [7/200], Step [171/202], Loss: 0.0298, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [174/202], Loss: 0.0989, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [7/200], Step [177/202], Loss: 0.1502, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [7/200], Step [180/202], Loss: 0.0815, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [7/200], Step [183/202], Loss: 0.0795, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [7/200], Step [186/202], Loss: 0.1113, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [7/200], Step [189/202], Loss: 0.1871, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [7/200], Step [192/202], Loss: 0.1450, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [7/200], Step [195/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [198/202], Loss: 0.0192, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [7/200], Step [201/202], Loss: 0.0437, Accuracy: 96.88%, F1_Score: 0.96\n",
      "------------Epoch Finish------------\n",
      "Epoch [7/200], Accuracy: 98.59%, F1_Score: 0.97\n",
      "Start validation #7\n",
      "Validation #7  Accuracy: 90.75% F1_Score: 0.86 Average Loss: 0.2901\n",
      "Epoch end..\n",
      "epoch time : 255.26054251904134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [31:26<14:19:55, 267.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [8/200], Step [3/202], Loss: 0.0099, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [6/202], Loss: 0.0118, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [9/202], Loss: 0.0128, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [12/202], Loss: 0.0088, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [15/202], Loss: 0.0311, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [18/202], Loss: 0.0282, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [21/202], Loss: 0.0080, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [24/202], Loss: 0.0056, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [27/202], Loss: 0.0109, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [30/202], Loss: 0.0089, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [33/202], Loss: 0.0030, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [36/202], Loss: 0.0095, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [39/202], Loss: 0.0190, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [42/202], Loss: 0.0838, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [8/200], Step [45/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [48/202], Loss: 0.0059, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [51/202], Loss: 0.0051, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [54/202], Loss: 0.0522, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [8/200], Step [57/202], Loss: 0.0547, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [8/200], Step [60/202], Loss: 0.1159, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [63/202], Loss: 0.0113, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [66/202], Loss: 0.0083, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [69/202], Loss: 0.0446, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [72/202], Loss: 0.1618, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [8/200], Step [75/202], Loss: 0.0159, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [78/202], Loss: 0.0351, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [81/202], Loss: 0.0325, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [84/202], Loss: 0.0253, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [87/202], Loss: 0.0069, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [90/202], Loss: 0.1260, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [93/202], Loss: 0.1238, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [8/200], Step [96/202], Loss: 0.0230, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [99/202], Loss: 0.0228, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [102/202], Loss: 0.0119, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [105/202], Loss: 0.0807, Accuracy: 96.88%, F1_Score: 0.94\n",
      "Epoch [8/200], Step [108/202], Loss: 0.0094, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [111/202], Loss: 0.1244, Accuracy: 90.62%, F1_Score: 0.82\n",
      "Epoch [8/200], Step [114/202], Loss: 0.0129, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [117/202], Loss: 0.0464, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [8/200], Step [120/202], Loss: 0.2020, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [8/200], Step [123/202], Loss: 0.1312, Accuracy: 93.75%, F1_Score: 0.91\n",
      "Epoch [8/200], Step [126/202], Loss: 0.0721, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [8/200], Step [129/202], Loss: 0.0914, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [8/200], Step [132/202], Loss: 0.0988, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [8/200], Step [135/202], Loss: 0.0341, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [8/200], Step [138/202], Loss: 0.0627, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [141/202], Loss: 0.0233, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [144/202], Loss: 0.0159, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [147/202], Loss: 0.0252, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [150/202], Loss: 0.0426, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [153/202], Loss: 0.1582, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [8/200], Step [156/202], Loss: 0.0065, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [159/202], Loss: 0.0136, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [162/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [165/202], Loss: 0.2102, Accuracy: 93.75%, F1_Score: 0.93\n",
      "Epoch [8/200], Step [168/202], Loss: 0.0087, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [171/202], Loss: 0.0164, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [174/202], Loss: 0.0037, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [177/202], Loss: 0.0064, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [180/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [183/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [186/202], Loss: 0.0095, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [189/202], Loss: 0.0093, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [192/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [8/200], Step [195/202], Loss: 0.0414, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [8/200], Step [198/202], Loss: 0.1738, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [8/200], Step [201/202], Loss: 0.0212, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [8/200], Accuracy: 98.62%, F1_Score: 0.98\n",
      "Start validation #8\n",
      "Validation #8  Accuracy: 95.25% F1_Score: 0.91 Average Loss: 0.1684\n",
      "Best performance at epoch: 8\n",
      "Save model in /opt/ml/level1-image-classification-level1-recsys-16/junghkim/model\n",
      "Epoch end..\n",
      "epoch time : 265.5358400239493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [36:01<14:22:53, 269.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [9/200], Step [3/202], Loss: 0.0211, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [6/202], Loss: 0.0359, Accuracy: 96.88%, F1_Score: 0.88\n",
      "Epoch [9/200], Step [9/202], Loss: 0.1048, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [9/200], Step [12/202], Loss: 0.0047, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [15/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [18/202], Loss: 0.1483, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [9/200], Step [21/202], Loss: 0.0767, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [9/200], Step [24/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [27/202], Loss: 0.1405, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [9/200], Step [30/202], Loss: 0.0160, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [33/202], Loss: 0.0157, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [36/202], Loss: 0.0145, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [39/202], Loss: 0.0138, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [42/202], Loss: 0.0074, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [45/202], Loss: 0.0067, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [48/202], Loss: 0.0339, Accuracy: 96.88%, F1_Score: 0.95\n",
      "Epoch [9/200], Step [51/202], Loss: 0.0150, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [54/202], Loss: 0.0296, Accuracy: 96.88%, F1_Score: 0.88\n",
      "Epoch [9/200], Step [57/202], Loss: 0.0255, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [9/200], Step [60/202], Loss: 0.0734, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [9/200], Step [63/202], Loss: 0.0352, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [9/200], Step [66/202], Loss: 0.0020, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [69/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [72/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [75/202], Loss: 0.0066, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [78/202], Loss: 0.0085, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [81/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [84/202], Loss: 0.0046, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [87/202], Loss: 0.0083, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [90/202], Loss: 0.1093, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [9/200], Step [93/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [96/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [99/202], Loss: 0.0271, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [102/202], Loss: 0.0048, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [105/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [108/202], Loss: 0.2732, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [9/200], Step [111/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [114/202], Loss: 0.0146, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [117/202], Loss: 0.0858, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [9/200], Step [120/202], Loss: 0.0103, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [123/202], Loss: 0.0065, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [126/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [129/202], Loss: 0.0132, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [132/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [135/202], Loss: 0.0054, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [138/202], Loss: 0.0223, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [141/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [144/202], Loss: 0.0165, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [147/202], Loss: 0.0253, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [150/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [153/202], Loss: 0.0618, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [9/200], Step [156/202], Loss: 0.0383, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [9/200], Step [159/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [162/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [165/202], Loss: 0.1119, Accuracy: 96.88%, F1_Score: 0.95\n",
      "Epoch [9/200], Step [168/202], Loss: 0.1088, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [9/200], Step [171/202], Loss: 0.1185, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [9/200], Step [174/202], Loss: 0.0182, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [177/202], Loss: 0.0609, Accuracy: 96.88%, F1_Score: 0.89\n",
      "Epoch [9/200], Step [180/202], Loss: 0.0200, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [183/202], Loss: 0.0218, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [186/202], Loss: 0.0289, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [9/200], Step [189/202], Loss: 0.1128, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [9/200], Step [192/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [195/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [9/200], Step [198/202], Loss: 0.1427, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [9/200], Step [201/202], Loss: 0.0107, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [9/200], Accuracy: 99.03%, F1_Score: 0.98\n",
      "Start validation #9\n",
      "Validation #9  Accuracy: 94.00% F1_Score: 0.91 Average Loss: 0.2005\n",
      "Epoch end..\n",
      "epoch time : 255.51020040002186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [40:25<14:13:45, 268.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [10/200], Step [3/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [6/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [9/202], Loss: 0.0047, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [12/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [15/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [18/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [21/202], Loss: 0.0368, Accuracy: 96.88%, F1_Score: 0.99\n",
      "Epoch [10/200], Step [24/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [27/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [30/202], Loss: 0.0107, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [33/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [36/202], Loss: 0.0225, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [39/202], Loss: 0.0061, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [42/202], Loss: 0.0123, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [45/202], Loss: 0.0166, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [48/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [51/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [54/202], Loss: 0.2150, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [10/200], Step [57/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [60/202], Loss: 0.4673, Accuracy: 87.50%, F1_Score: 0.81\n",
      "Epoch [10/200], Step [63/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [66/202], Loss: 0.0150, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [69/202], Loss: 0.0465, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [10/200], Step [72/202], Loss: 0.0356, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [10/200], Step [75/202], Loss: 0.0075, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [78/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [81/202], Loss: 0.1308, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [10/200], Step [84/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [87/202], Loss: 0.0757, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [10/200], Step [90/202], Loss: 0.2769, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [10/200], Step [93/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [96/202], Loss: 0.0580, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [10/200], Step [99/202], Loss: 0.0292, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [10/200], Step [102/202], Loss: 0.0616, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [10/200], Step [105/202], Loss: 0.0415, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [10/200], Step [108/202], Loss: 0.0065, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [111/202], Loss: 0.0337, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [114/202], Loss: 0.1623, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [10/200], Step [117/202], Loss: 0.0586, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [10/200], Step [120/202], Loss: 0.0173, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [123/202], Loss: 0.0141, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [126/202], Loss: 0.0983, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [10/200], Step [129/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [132/202], Loss: 0.0227, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [135/202], Loss: 0.0397, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [138/202], Loss: 0.0090, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [141/202], Loss: 0.0983, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [10/200], Step [144/202], Loss: 0.0461, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [10/200], Step [147/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [150/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [153/202], Loss: 0.0179, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [156/202], Loss: 0.0486, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [10/200], Step [159/202], Loss: 0.1711, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [10/200], Step [162/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [165/202], Loss: 0.0919, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [10/200], Step [168/202], Loss: 0.1729, Accuracy: 96.88%, F1_Score: 0.86\n",
      "Epoch [10/200], Step [171/202], Loss: 0.2339, Accuracy: 90.62%, F1_Score: 0.80\n",
      "Epoch [10/200], Step [174/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [177/202], Loss: 0.0455, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [10/200], Step [180/202], Loss: 0.0956, Accuracy: 96.88%, F1_Score: 0.93\n",
      "Epoch [10/200], Step [183/202], Loss: 0.1334, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [10/200], Step [186/202], Loss: 0.0057, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [189/202], Loss: 0.0469, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [192/202], Loss: 0.0651, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [10/200], Step [195/202], Loss: 0.0405, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [198/202], Loss: 0.0111, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [10/200], Step [201/202], Loss: 0.0092, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [10/200], Accuracy: 98.59%, F1_Score: 0.98\n",
      "Start validation #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [44:41<13:57:47, 264.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #10  Accuracy: 93.00% F1_Score: 0.88 Average Loss: 0.2977\n",
      "Epoch end..\n",
      "epoch time : 256.1015674879891\n",
      "Epoch start..\n",
      "Epoch [11/200], Step [3/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [6/202], Loss: 0.0060, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [9/202], Loss: 0.3128, Accuracy: 96.88%, F1_Score: 0.89\n",
      "Epoch [11/200], Step [12/202], Loss: 0.0294, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [11/200], Step [15/202], Loss: 0.0749, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [11/200], Step [18/202], Loss: 0.0269, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [21/202], Loss: 0.0210, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [24/202], Loss: 0.0114, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [27/202], Loss: 0.0096, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [30/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [33/202], Loss: 0.0490, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [11/200], Step [36/202], Loss: 0.0746, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [11/200], Step [39/202], Loss: 0.1115, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [11/200], Step [42/202], Loss: 0.0169, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [45/202], Loss: 0.0495, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [11/200], Step [48/202], Loss: 0.0205, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [51/202], Loss: 0.0508, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [11/200], Step [54/202], Loss: 0.0082, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [57/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [60/202], Loss: 0.0138, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [63/202], Loss: 0.0687, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [11/200], Step [66/202], Loss: 0.0077, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [69/202], Loss: 0.0090, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [72/202], Loss: 0.0060, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [75/202], Loss: 0.0076, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [78/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [81/202], Loss: 0.0244, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [84/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [87/202], Loss: 0.0198, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [90/202], Loss: 0.0078, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [93/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [96/202], Loss: 0.0155, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [99/202], Loss: 0.0210, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [102/202], Loss: 0.0119, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [105/202], Loss: 0.0128, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [108/202], Loss: 0.0150, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [111/202], Loss: 0.0039, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [114/202], Loss: 0.0111, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [117/202], Loss: 0.0521, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [11/200], Step [120/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [123/202], Loss: 0.0084, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [126/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [129/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [132/202], Loss: 0.0059, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [135/202], Loss: 0.0236, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [138/202], Loss: 0.0072, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [141/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [144/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [147/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [150/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [153/202], Loss: 0.0546, Accuracy: 96.88%, F1_Score: 0.99\n",
      "Epoch [11/200], Step [156/202], Loss: 0.0510, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [11/200], Step [159/202], Loss: 0.1240, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [11/200], Step [162/202], Loss: 0.0035, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [165/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [168/202], Loss: 0.0201, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [171/202], Loss: 0.0513, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [11/200], Step [174/202], Loss: 0.0127, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [177/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [180/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [183/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [186/202], Loss: 0.0054, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [189/202], Loss: 0.0109, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [192/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [195/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [11/200], Step [198/202], Loss: 0.2284, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [11/200], Step [201/202], Loss: 0.5522, Accuracy: 87.50%, F1_Score: 0.79\n",
      "------------Epoch Finish------------\n",
      "Epoch [11/200], Accuracy: 99.09%, F1_Score: 0.98\n",
      "Start validation #11\n",
      "Validation #11  Accuracy: 94.94% F1_Score: 0.92 Average Loss: 0.2041\n",
      "Epoch end..\n",
      "epoch time : 255.61697975097923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [49:06<13:53:36, 264.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [12/200], Step [3/202], Loss: 0.1455, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [6/202], Loss: 0.0214, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [9/202], Loss: 0.0042, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [12/202], Loss: 0.0568, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [15/202], Loss: 0.0046, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [18/202], Loss: 0.0494, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [21/202], Loss: 0.0266, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [24/202], Loss: 0.0155, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [27/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [30/202], Loss: 0.0243, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [33/202], Loss: 0.0078, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [36/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [39/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [42/202], Loss: 0.0218, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [45/202], Loss: 0.0109, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [48/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [51/202], Loss: 0.0124, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [54/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [57/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [60/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [63/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [66/202], Loss: 0.0046, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [69/202], Loss: 0.0103, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [72/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [75/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [78/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [81/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [84/202], Loss: 0.0043, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [87/202], Loss: 0.0749, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [90/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [93/202], Loss: 0.3198, Accuracy: 93.75%, F1_Score: 0.81\n",
      "Epoch [12/200], Step [96/202], Loss: 0.0330, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [99/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [102/202], Loss: 0.0030, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [105/202], Loss: 0.1308, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [12/200], Step [108/202], Loss: 0.1575, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [12/200], Step [111/202], Loss: 0.0286, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [114/202], Loss: 0.1584, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [12/200], Step [117/202], Loss: 0.0113, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [120/202], Loss: 0.1887, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [123/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [126/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [129/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [132/202], Loss: 0.0325, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [12/200], Step [135/202], Loss: 0.0665, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [12/200], Step [138/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [141/202], Loss: 0.0090, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [144/202], Loss: 0.0495, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [147/202], Loss: 0.0756, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [12/200], Step [150/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [153/202], Loss: 0.0239, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [156/202], Loss: 0.0102, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [159/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [162/202], Loss: 0.0380, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [12/200], Step [165/202], Loss: 0.0540, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [12/200], Step [168/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [171/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [174/202], Loss: 0.0084, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [177/202], Loss: 0.0193, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [180/202], Loss: 0.0046, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [183/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [186/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [189/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [192/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [195/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [198/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [12/200], Step [201/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [12/200], Accuracy: 99.21%, F1_Score: 0.99\n",
      "Start validation #12\n",
      "Validation #12  Accuracy: 95.19% F1_Score: 0.91 Average Loss: 0.1879\n",
      "Epoch end..\n",
      "epoch time : 255.4445098080323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [53:31<13:49:03, 264.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [13/200], Step [3/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [6/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [9/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [12/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [15/202], Loss: 0.0606, Accuracy: 96.88%, F1_Score: 0.93\n",
      "Epoch [13/200], Step [18/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [21/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [24/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [27/202], Loss: 0.0005, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [30/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [33/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [36/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [39/202], Loss: 0.0020, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [42/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [45/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [48/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [51/202], Loss: 0.0534, Accuracy: 96.88%, F1_Score: 0.94\n",
      "Epoch [13/200], Step [54/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [57/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [60/202], Loss: 0.0543, Accuracy: 93.75%, F1_Score: 0.82\n",
      "Epoch [13/200], Step [63/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [66/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [69/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [72/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [75/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [78/202], Loss: 0.0046, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [81/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [84/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [87/202], Loss: 0.0091, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [90/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [93/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [96/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [99/202], Loss: 0.0125, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [102/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [105/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [108/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [111/202], Loss: 0.0057, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [114/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [117/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [120/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [123/202], Loss: 0.0154, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [126/202], Loss: 0.2451, Accuracy: 93.75%, F1_Score: 0.87\n",
      "Epoch [13/200], Step [129/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [132/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [135/202], Loss: 0.0338, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [13/200], Step [138/202], Loss: 0.0077, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [141/202], Loss: 0.0712, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [13/200], Step [144/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [147/202], Loss: 0.0273, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [150/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [153/202], Loss: 0.0079, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [156/202], Loss: 0.0491, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [13/200], Step [159/202], Loss: 0.0197, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [162/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [165/202], Loss: 0.2805, Accuracy: 90.62%, F1_Score: 0.87\n",
      "Epoch [13/200], Step [168/202], Loss: 0.0982, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [13/200], Step [171/202], Loss: 0.0030, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [174/202], Loss: 0.0696, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [13/200], Step [177/202], Loss: 0.0020, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [180/202], Loss: 0.1269, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [13/200], Step [183/202], Loss: 0.1451, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [13/200], Step [186/202], Loss: 0.0221, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [189/202], Loss: 0.0469, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [13/200], Step [192/202], Loss: 0.0063, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [13/200], Step [195/202], Loss: 0.1230, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [13/200], Step [198/202], Loss: 0.1808, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [13/200], Step [201/202], Loss: 0.0121, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [13/200], Accuracy: 99.12%, F1_Score: 0.99\n",
      "Start validation #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [57:47<13:36:30, 261.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #13  Accuracy: 93.69% F1_Score: 0.89 Average Loss: 0.2453\n",
      "Epoch end..\n",
      "epoch time : 255.87480266898638\n",
      "Epoch start..\n",
      "Epoch [14/200], Step [3/202], Loss: 0.0160, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [6/202], Loss: 0.0415, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [14/200], Step [9/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [12/202], Loss: 0.0375, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [14/200], Step [15/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [18/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [21/202], Loss: 0.0135, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [24/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [27/202], Loss: 0.0531, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [30/202], Loss: 0.1429, Accuracy: 93.75%, F1_Score: 0.96\n",
      "Epoch [14/200], Step [33/202], Loss: 0.0350, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [36/202], Loss: 0.2102, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [14/200], Step [39/202], Loss: 0.1776, Accuracy: 96.88%, F1_Score: 0.83\n",
      "Epoch [14/200], Step [42/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [45/202], Loss: 0.0295, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [14/200], Step [48/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [51/202], Loss: 0.0256, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [54/202], Loss: 0.0083, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [57/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [60/202], Loss: 0.0145, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [63/202], Loss: 0.0465, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [14/200], Step [66/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [69/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [72/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [75/202], Loss: 0.0422, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [14/200], Step [78/202], Loss: 0.0125, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [81/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [84/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [87/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [90/202], Loss: 0.0268, Accuracy: 96.88%, F1_Score: 0.86\n",
      "Epoch [14/200], Step [93/202], Loss: 0.0093, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [96/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [99/202], Loss: 0.0188, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [102/202], Loss: 0.0047, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [105/202], Loss: 0.0616, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [14/200], Step [108/202], Loss: 0.0791, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [111/202], Loss: 0.0072, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [114/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [117/202], Loss: 0.0269, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [14/200], Step [120/202], Loss: 0.0438, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [123/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [126/202], Loss: 0.2344, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [129/202], Loss: 0.0043, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [132/202], Loss: 0.0900, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [135/202], Loss: 0.0691, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [14/200], Step [138/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [141/202], Loss: 0.0337, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [14/200], Step [144/202], Loss: 0.2433, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [14/200], Step [147/202], Loss: 0.0037, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [150/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [153/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [156/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [159/202], Loss: 0.0752, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [14/200], Step [162/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [165/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [168/202], Loss: 0.0348, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [14/200], Step [171/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [174/202], Loss: 0.0111, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [177/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [180/202], Loss: 0.0292, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [183/202], Loss: 0.0047, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [186/202], Loss: 0.0188, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [189/202], Loss: 0.0037, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [192/202], Loss: 0.0076, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [195/202], Loss: 0.1099, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [14/200], Step [198/202], Loss: 0.0060, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [14/200], Step [201/202], Loss: 0.0095, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [14/200], Accuracy: 98.90%, F1_Score: 0.98\n",
      "Start validation #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [1:02:03<13:26:27, 260.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #14  Accuracy: 93.88% F1_Score: 0.89 Average Loss: 0.2394\n",
      "Epoch end..\n",
      "epoch time : 255.8802313330234\n",
      "Epoch start..\n",
      "Epoch [15/200], Step [3/202], Loss: 0.0094, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [6/202], Loss: 0.0140, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [9/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [12/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [15/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [18/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [21/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [24/202], Loss: 0.0124, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [27/202], Loss: 0.0066, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [30/202], Loss: 0.0228, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [33/202], Loss: 0.0106, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [36/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [39/202], Loss: 0.0168, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [42/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [45/202], Loss: 0.0217, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [48/202], Loss: 0.0071, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [51/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [54/202], Loss: 0.0149, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [57/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [60/202], Loss: 0.0147, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [63/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [66/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [69/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [72/202], Loss: 0.0211, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [75/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [78/202], Loss: 0.0223, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [81/202], Loss: 0.0683, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [15/200], Step [84/202], Loss: 0.0124, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [87/202], Loss: 0.0321, Accuracy: 96.88%, F1_Score: 0.85\n",
      "Epoch [15/200], Step [90/202], Loss: 0.0911, Accuracy: 96.88%, F1_Score: 0.93\n",
      "Epoch [15/200], Step [93/202], Loss: 0.1289, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [15/200], Step [96/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [99/202], Loss: 0.0061, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [102/202], Loss: 0.0121, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [105/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [108/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [111/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [114/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [117/202], Loss: 0.0039, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [120/202], Loss: 0.0341, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [15/200], Step [123/202], Loss: 0.0127, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [126/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [129/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [132/202], Loss: 0.0020, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [135/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [138/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [141/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [144/202], Loss: 0.0277, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [15/200], Step [147/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [150/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [153/202], Loss: 0.0116, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [156/202], Loss: 0.0259, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [15/200], Step [159/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [162/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [165/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [168/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [171/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [174/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [177/202], Loss: 0.0671, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [15/200], Step [180/202], Loss: 0.0042, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [183/202], Loss: 0.3544, Accuracy: 90.62%, F1_Score: 0.83\n",
      "Epoch [15/200], Step [186/202], Loss: 0.0384, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [15/200], Step [189/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [192/202], Loss: 0.0122, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [15/200], Step [195/202], Loss: 0.1267, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [15/200], Step [198/202], Loss: 0.0942, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [15/200], Step [201/202], Loss: 0.0231, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [15/200], Accuracy: 99.33%, F1_Score: 0.99\n",
      "Start validation #15\n",
      "Validation #15  Accuracy: 94.06% F1_Score: 0.90 Average Loss: 0.2410\n",
      "Epoch end..\n",
      "epoch time : 255.0747985090129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [1:06:30<13:28:42, 262.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [16/200], Step [3/202], Loss: 0.0169, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [6/202], Loss: 0.0069, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [9/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [12/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [15/202], Loss: 0.0349, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [16/200], Step [18/202], Loss: 0.0124, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [21/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [24/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [27/202], Loss: 0.0946, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [16/200], Step [30/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [33/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [36/202], Loss: 0.0421, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [16/200], Step [39/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [42/202], Loss: 0.0058, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [45/202], Loss: 0.1534, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [16/200], Step [48/202], Loss: 0.0263, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [51/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [54/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [57/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [60/202], Loss: 0.0039, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [63/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [66/202], Loss: 0.0141, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [69/202], Loss: 0.0088, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [72/202], Loss: 0.0048, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [75/202], Loss: 0.0267, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [78/202], Loss: 0.0111, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [81/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [84/202], Loss: 0.0984, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [16/200], Step [87/202], Loss: 0.1320, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [16/200], Step [90/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [93/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [96/202], Loss: 0.0503, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [16/200], Step [99/202], Loss: 0.0100, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [102/202], Loss: 0.0806, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [16/200], Step [105/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [108/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [111/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [114/202], Loss: 0.0073, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [117/202], Loss: 0.0147, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [120/202], Loss: 0.0221, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [123/202], Loss: 0.0179, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [126/202], Loss: 0.0042, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [129/202], Loss: 0.0096, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [132/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [135/202], Loss: 0.0130, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [138/202], Loss: 0.0285, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [16/200], Step [141/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [144/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [147/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [150/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [153/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [156/202], Loss: 0.0035, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [159/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [162/202], Loss: 0.0023, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [165/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [168/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [171/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [174/202], Loss: 0.0092, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [177/202], Loss: 0.0902, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [16/200], Step [180/202], Loss: 0.1581, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [16/200], Step [183/202], Loss: 0.0096, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [186/202], Loss: 0.0109, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [189/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [192/202], Loss: 0.1889, Accuracy: 96.88%, F1_Score: 0.89\n",
      "Epoch [16/200], Step [195/202], Loss: 0.0285, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [198/202], Loss: 0.0135, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [16/200], Step [201/202], Loss: 0.0152, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [16/200], Accuracy: 99.32%, F1_Score: 0.99\n",
      "Start validation #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [1:10:45<13:17:40, 260.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #16  Accuracy: 93.69% F1_Score: 0.90 Average Loss: 0.2556\n",
      "Epoch end..\n",
      "epoch time : 255.047962311015\n",
      "Epoch start..\n",
      "Epoch [17/200], Step [3/202], Loss: 0.0868, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [17/200], Step [6/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [9/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [12/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [15/202], Loss: 0.0199, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [18/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [21/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [24/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [27/202], Loss: 0.0024, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [30/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [33/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [36/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [39/202], Loss: 0.0033, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [42/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [45/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [48/202], Loss: 0.0056, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [51/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [54/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [57/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [60/202], Loss: 0.0170, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [63/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [66/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [69/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [72/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [75/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [78/202], Loss: 0.0092, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [81/202], Loss: 0.0074, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [84/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [87/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [90/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [93/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [96/202], Loss: 0.1202, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [17/200], Step [99/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [102/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [105/202], Loss: 0.0284, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [17/200], Step [108/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [111/202], Loss: 0.0106, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [114/202], Loss: 0.0063, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [117/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [120/202], Loss: 0.0031, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [123/202], Loss: 0.0030, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [126/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [129/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [132/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [135/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [138/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [141/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [144/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [147/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [150/202], Loss: 0.1663, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [17/200], Step [153/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [156/202], Loss: 0.0166, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [159/202], Loss: 0.0065, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [162/202], Loss: 0.0995, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [17/200], Step [165/202], Loss: 0.0027, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [168/202], Loss: 0.1205, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [17/200], Step [171/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [174/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [177/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [180/202], Loss: 0.0037, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [183/202], Loss: 0.0077, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [186/202], Loss: 0.0039, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [189/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [192/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [195/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [198/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [17/200], Step [201/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [17/200], Accuracy: 99.46%, F1_Score: 0.99\n",
      "Start validation #17\n",
      "Validation #17  Accuracy: 96.06% F1_Score: 0.93 Average Loss: 0.1930\n",
      "Epoch end..\n",
      "epoch time : 254.77671405294677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [1:15:09<13:16:59, 261.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch start..\n",
      "Epoch [18/200], Step [3/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [6/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [9/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [12/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [15/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [18/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [21/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [24/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [27/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [30/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [33/202], Loss: 0.0066, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [36/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [39/202], Loss: 0.0156, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [42/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [45/202], Loss: 0.0004, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [48/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [51/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [54/202], Loss: 0.0004, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [57/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [60/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [63/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [66/202], Loss: 0.0076, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [69/202], Loss: 0.0182, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [72/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [75/202], Loss: 0.0065, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [78/202], Loss: 0.0103, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [81/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [84/202], Loss: 0.0045, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [87/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [90/202], Loss: 0.0265, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [18/200], Step [93/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [96/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [99/202], Loss: 0.0152, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [102/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [105/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [108/202], Loss: 0.0514, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [18/200], Step [111/202], Loss: 0.1618, Accuracy: 93.75%, F1_Score: 0.95\n",
      "Epoch [18/200], Step [114/202], Loss: 0.0043, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [117/202], Loss: 0.1179, Accuracy: 93.75%, F1_Score: 0.86\n",
      "Epoch [18/200], Step [120/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [123/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [126/202], Loss: 0.0056, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [129/202], Loss: 0.0270, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [132/202], Loss: 0.0510, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [18/200], Step [135/202], Loss: 0.0503, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [18/200], Step [138/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [141/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [144/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [147/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [150/202], Loss: 0.0268, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [18/200], Step [153/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [156/202], Loss: 0.0096, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [159/202], Loss: 0.0104, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [162/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [165/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [168/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [171/202], Loss: 0.0151, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [174/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [177/202], Loss: 0.2051, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [18/200], Step [180/202], Loss: 0.0872, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [18/200], Step [183/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [186/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [189/202], Loss: 0.0956, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [18/200], Step [192/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [195/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [18/200], Step [198/202], Loss: 0.1011, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [18/200], Step [201/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [18/200], Accuracy: 99.23%, F1_Score: 0.99\n",
      "Start validation #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [1:19:24<13:07:11, 259.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #18  Accuracy: 93.31% F1_Score: 0.89 Average Loss: 0.2892\n",
      "Epoch end..\n",
      "epoch time : 255.31997692101868\n",
      "Epoch start..\n",
      "Epoch [19/200], Step [3/202], Loss: 0.0059, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [6/202], Loss: 0.0055, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [9/202], Loss: 0.0041, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [12/202], Loss: 0.0016, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [15/202], Loss: 0.0502, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [19/200], Step [18/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [21/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [24/202], Loss: 0.0317, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [19/200], Step [27/202], Loss: 0.0444, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [19/200], Step [30/202], Loss: 0.0005, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [33/202], Loss: 0.0066, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [36/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [39/202], Loss: 0.0541, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [19/200], Step [42/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [45/202], Loss: 0.0971, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [19/200], Step [48/202], Loss: 0.0153, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [51/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [54/202], Loss: 0.1803, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [19/200], Step [57/202], Loss: 0.1225, Accuracy: 93.75%, F1_Score: 0.83\n",
      "Epoch [19/200], Step [60/202], Loss: 0.3563, Accuracy: 93.75%, F1_Score: 0.90\n",
      "Epoch [19/200], Step [63/202], Loss: 0.0051, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [66/202], Loss: 0.2045, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [19/200], Step [69/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [72/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [75/202], Loss: 0.1920, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [19/200], Step [78/202], Loss: 0.1152, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [19/200], Step [81/202], Loss: 0.0035, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [84/202], Loss: 0.0021, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [87/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [90/202], Loss: 0.0057, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [93/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [96/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [99/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [102/202], Loss: 0.0671, Accuracy: 96.88%, F1_Score: 0.92\n",
      "Epoch [19/200], Step [105/202], Loss: 0.0090, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [108/202], Loss: 0.0069, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [111/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [114/202], Loss: 0.0094, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [117/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [120/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [123/202], Loss: 0.0075, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [126/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [129/202], Loss: 0.0161, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [132/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [135/202], Loss: 0.0043, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [138/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [141/202], Loss: 0.0026, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [144/202], Loss: 0.0195, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [147/202], Loss: 0.0025, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [150/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [153/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [156/202], Loss: 0.0008, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [159/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [162/202], Loss: 0.0258, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [165/202], Loss: 0.0140, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [168/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [171/202], Loss: 0.0006, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [174/202], Loss: 0.0238, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [177/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [180/202], Loss: 0.0009, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [183/202], Loss: 0.0010, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [186/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [189/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [192/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [195/202], Loss: 0.0003, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [198/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [19/200], Step [201/202], Loss: 0.0052, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [19/200], Accuracy: 99.30%, F1_Score: 0.98\n",
      "Start validation #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [1:23:40<12:59:38, 258.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #19  Accuracy: 95.25% F1_Score: 0.92 Average Loss: 0.2375\n",
      "Epoch end..\n",
      "epoch time : 255.9556160949869\n",
      "Epoch start..\n",
      "Epoch [20/200], Step [3/202], Loss: 0.0005, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [6/202], Loss: 0.0053, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [9/202], Loss: 0.0813, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [12/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [15/202], Loss: 0.1429, Accuracy: 93.75%, F1_Score: 0.94\n",
      "Epoch [20/200], Step [18/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [21/202], Loss: 0.0044, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [24/202], Loss: 0.0302, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [27/202], Loss: 0.0390, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [30/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [33/202], Loss: 0.0036, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [36/202], Loss: 0.0017, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [39/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [42/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [45/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [48/202], Loss: 0.0285, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [51/202], Loss: 0.0013, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [54/202], Loss: 0.0018, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [57/202], Loss: 0.2216, Accuracy: 96.88%, F1_Score: 0.98\n",
      "Epoch [20/200], Step [60/202], Loss: 0.3053, Accuracy: 93.75%, F1_Score: 0.92\n",
      "Epoch [20/200], Step [63/202], Loss: 0.0019, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [66/202], Loss: 0.0160, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [69/202], Loss: 0.0102, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [72/202], Loss: 0.0980, Accuracy: 93.75%, F1_Score: 0.88\n",
      "Epoch [20/200], Step [75/202], Loss: 0.0688, Accuracy: 96.88%, F1_Score: 0.90\n",
      "Epoch [20/200], Step [78/202], Loss: 0.0113, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [81/202], Loss: 0.0100, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [84/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [87/202], Loss: 0.0034, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [90/202], Loss: 0.0657, Accuracy: 96.88%, F1_Score: 0.96\n",
      "Epoch [20/200], Step [93/202], Loss: 0.0082, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [96/202], Loss: 0.0777, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [99/202], Loss: 0.0264, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [102/202], Loss: 0.0148, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [105/202], Loss: 0.0030, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [108/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [111/202], Loss: 0.0032, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [114/202], Loss: 0.0020, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [117/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [120/202], Loss: 0.0073, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [123/202], Loss: 0.0118, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [126/202], Loss: 0.0049, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [129/202], Loss: 0.0022, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [132/202], Loss: 0.0063, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [135/202], Loss: 0.1445, Accuracy: 93.75%, F1_Score: 0.89\n",
      "Epoch [20/200], Step [138/202], Loss: 0.0147, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [141/202], Loss: 0.0154, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [144/202], Loss: 0.0040, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [147/202], Loss: 0.0011, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [150/202], Loss: 0.0094, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [153/202], Loss: 0.0138, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [156/202], Loss: 0.0351, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [159/202], Loss: 0.0162, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [162/202], Loss: 0.0029, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [165/202], Loss: 0.0038, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [168/202], Loss: 0.1251, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [171/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [174/202], Loss: 0.0578, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [20/200], Step [177/202], Loss: 0.0105, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [180/202], Loss: 0.0028, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [183/202], Loss: 0.0356, Accuracy: 96.88%, F1_Score: 0.97\n",
      "Epoch [20/200], Step [186/202], Loss: 0.0014, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [189/202], Loss: 0.0050, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [192/202], Loss: 0.0546, Accuracy: 96.88%, F1_Score: 0.91\n",
      "Epoch [20/200], Step [195/202], Loss: 0.0012, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [198/202], Loss: 0.0015, Accuracy: 100.00%, F1_Score: 1.00\n",
      "Epoch [20/200], Step [201/202], Loss: 0.0007, Accuracy: 100.00%, F1_Score: 1.00\n",
      "------------Epoch Finish------------\n",
      "Epoch [20/200], Accuracy: 99.27%, F1_Score: 0.99\n",
      "Start validation #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [1:27:56<13:57:45, 277.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation #20  Accuracy: 95.25% F1_Score: 0.92 Average Loss: 0.2375\n",
      "Epoch end..\n",
      "epoch time : 255.72786000499036\n",
      "early_stopped\n",
      "End training..\n",
      "total time : 5276.444389826036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, model, train_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb6573b-fbad-4ab9-b53b-1458321a8779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/model/best_modelvit.pt'\n",
    "checkpoint = torch.load(model_path,map_location=device)\n",
    "state_dict = checkpoint['net']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e7f3d18-5ddd-437c-a9af-75cdaafeb97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in test_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submit_dir = '/opt/ml/level1-image-classification-level1-recsys-16/junghkim/submit'\n",
    "submission.to_csv(os.path.join(submit_dir, 'submissionvit.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49871ff6-169a-44c3-88b1-a5fdf7176e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
